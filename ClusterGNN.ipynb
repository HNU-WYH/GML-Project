{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46va4TNEroil"
      },
      "outputs": [],
      "source": [
        "#Install dependencies\n",
        "%pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "28eMWuRem-Ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f742005-407d-465f-e478-852fa06927af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iaxf2wAsOnoB"
      },
      "outputs": [],
      "source": [
        "!pip3 uninstall numml\n",
        "!git clone https://github.com/nicknytko/numml.git\n",
        "%cd numml/\n",
        "!pip3 install .\n",
        "%cd ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MsEPU1MfRNbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f66310-5031-4430-d779-c19cfe7db01c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ilupp\n",
            "  Downloading ilupp-1.0.2.tar.gz (155 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.11/dist-packages (from ilupp) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ilupp) (1.15.3)\n",
            "Building wheels for collected packages: ilupp\n",
            "  Building wheel for ilupp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ilupp: filename=ilupp-1.0.2-cp311-cp311-linux_x86_64.whl size=3237628 sha256=26328801784c1609940f6b29e2a4460202fc1be7b22caaa9d15a62ed7d5c80f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/29/86/ee4ba827a16c7450e9750424fd645ce86fc0d958fadf3e9f9c\n",
            "Successfully built ilupp\n",
            "Installing collected packages: ilupp\n",
            "Successfully installed ilupp-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ilupp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1roIjAgFrUyo"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "import pprint\n",
        "import time\n",
        "\n",
        "import ilupp\n",
        "import numpy as np\n",
        "import scipy\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg\n",
        "from torch_geometric.nn import aggr\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.data import Batch\n",
        "from scipy.sparse import tril, coo_matrix\n",
        "\n",
        "\n",
        "from apps.data import get_dataloader, FolderDataset\n",
        "from apps.data import graph_to_matrix, matrix_to_graph\n",
        "\n",
        "from neuralif.utils import (\n",
        "    count_parameters, save_dict_to_file,\n",
        "    condition_number, eigenval_distribution, gershgorin_norm,\n",
        "    TwoHop\n",
        ")\n",
        "from neuralif.logger import TrainResults, TestResults\n",
        "from neuralif.loss import loss\n",
        "\n",
        "from krylov.cg import preconditioned_conjugate_gradient\n",
        "from krylov.gmres import gmres\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BkzbH3NXsI_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48722c73-c290-4cd2-eb65-6438b731ffc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "#Select GPU as device to run code\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq2MuVnxurF-"
      },
      "source": [
        "# **DATA GENERATION**\n",
        "Data has been pregenerated and put into github to prevent long time taken to re-generate matrices. If another dataset is to be generated, use the following code ot generate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsfJcpntsQhs"
      },
      "outputs": [],
      "source": [
        "#Generate matrices (This function takes a long time. The dataset has been pregenerated and put into our github repo)\n",
        "#from apps.synthetic import create_dataset\n",
        "\n",
        "# mat_size = 10_000\n",
        "# density = 10e-4\n",
        "\n",
        "# create_dataset(mat_size, 1000, alpha=density, mode='train', rs=0, graph=True, solution=True)\n",
        "# create_dataset(mat_size, 10, alpha=density, mode='val', rs=10000, graph=True, solution=True)\n",
        "# create_dataset(mat_size, 100, alpha=density, mode='test', rs=103600, graph=True, solution=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNbJhhNlvEbL"
      },
      "source": [
        "# **GRAPH NETWORK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RZIo8ZefvAsQ"
      },
      "outputs": [],
      "source": [
        "class GraphNet(nn.Module):\n",
        "    # Follows roughly the outline of torch_geometric.nn.MessagePassing()\n",
        "    # As shown in https://github.com/deepmind/graph_nets\n",
        "    # Here is a helpful python implementation:\n",
        "    # https://github.com/NVIDIA/GraphQSat/blob/main/gqsat/models.py\n",
        "    # Also allows multirgaph GNN via edge_2_features\n",
        "    def __init__(self, node_features, edge_features, global_features=0, hidden_size=0,\n",
        "                 aggregate=\"mean\", activation=\"relu\", skip_connection=False, edge_features_out=None):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # different aggregation functions\n",
        "        if aggregate == \"sum\":\n",
        "            self.aggregate = aggr.SumAggregation()\n",
        "        elif aggregate == \"mean\":\n",
        "            self.aggregate = aggr.MeanAggregation()\n",
        "        elif aggregate == \"max\":\n",
        "            self.aggregate = aggr.MaxAggregation()\n",
        "        elif aggregate == \"softmax\":\n",
        "            self.aggregate = aggr.SoftmaxAggregation(learn=True)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Aggregation '{aggregate}' not implemented\")\n",
        "\n",
        "        self.global_aggregate = aggr.MeanAggregation()\n",
        "\n",
        "        add_edge_fs = 1 if skip_connection else 0\n",
        "        edge_features_out = edge_features if edge_features_out is None else edge_features_out\n",
        "\n",
        "        # Graph Net Blocks (see https://arxiv.org/pdf/1806.01261.pdf)\n",
        "        self.edge_block = MLP([global_features + (edge_features + add_edge_fs) + (2 * node_features),\n",
        "                               hidden_size,\n",
        "                               edge_features_out],\n",
        "                              activation=activation)\n",
        "\n",
        "        self.node_block = MLP([global_features + edge_features_out + node_features,\n",
        "                               hidden_size,\n",
        "                               node_features],\n",
        "                              activation=activation)\n",
        "\n",
        "        # optional set of blocks for global GNN\n",
        "        self.global_block = None\n",
        "        if global_features > 0:\n",
        "            self.global_block = MLP([edge_features_out + node_features + global_features,\n",
        "                                     hidden_size,\n",
        "                                     global_features],\n",
        "                                    activation=activation)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, g=None):\n",
        "        row, col = edge_index\n",
        "\n",
        "        if self.global_block is not None:\n",
        "            assert g is not None, \"Need global features for global block\"\n",
        "\n",
        "            # run the edge update and aggregate features\n",
        "            edge_embedding = self.edge_block(torch.cat([torch.ones(x[row].shape[0], 1, device=x.device) * g,\n",
        "                                                        x[row], x[col], edge_attr], dim=1))\n",
        "            aggregation = self.aggregate(edge_embedding, row)\n",
        "\n",
        "\n",
        "            agg_features = torch.cat([torch.ones(x.shape[0], 1, device=x.device) * g, x, aggregation], dim=1)\n",
        "            node_embeddings = self.node_block(agg_features)\n",
        "\n",
        "            # aggregate over all edges and nodes (always mean)\n",
        "            mp_global_aggr = g\n",
        "            edge_aggregation_global = self.global_aggregate(edge_embedding)\n",
        "            node_aggregation_global = self.global_aggregate(node_embeddings)\n",
        "\n",
        "            # compute the new global embedding\n",
        "            # the old global feature is part of mp_global_aggr\n",
        "            global_embeddings = self.global_block(torch.cat([node_aggregation_global,\n",
        "                                                             edge_aggregation_global,\n",
        "                                                             mp_global_aggr], dim=1))\n",
        "\n",
        "            return edge_embedding, node_embeddings, global_embeddings\n",
        "\n",
        "        else:\n",
        "            # update edge features and aggregate\n",
        "            edge_embedding = self.edge_block(torch.cat([x[row], x[col], edge_attr], dim=1))\n",
        "            aggregation = self.aggregate(edge_embedding, row)\n",
        "            agg_features = torch.cat([x, aggregation], dim=1)\n",
        "            # update node features\n",
        "            node_embeddings = self.node_block(agg_features)\n",
        "            return edge_embedding, node_embeddings, None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g3PoZzRqvKDf"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, width, layer_norm=False, activation=\"relu\", activate_final=False):\n",
        "        super().__init__()\n",
        "        width = list(filter(lambda x: x > 0, width))\n",
        "        assert len(width) >= 2, \"Need at least one layer in the network!\"\n",
        "\n",
        "        lls = nn.ModuleList()\n",
        "        for k in range(len(width)-1):\n",
        "            lls.append(nn.Linear(width[k], width[k+1], bias=True))\n",
        "            if k != (len(width)-2) or activate_final:\n",
        "                if activation == \"relu\":\n",
        "                    lls.append(nn.ReLU())\n",
        "                elif activation == \"tanh\":\n",
        "                    lls.append(nn.Tanh())\n",
        "                elif activation == \"leakyrelu\":\n",
        "                    lls.append(nn.LeakyReLU())\n",
        "                elif activation == \"sigmoid\":\n",
        "                    lls.append(nn.Sigmoid())\n",
        "                else:\n",
        "                    raise NotImplementedError(f\"Activation '{activation}' not implemented\")\n",
        "\n",
        "        if layer_norm:\n",
        "            lls.append(nn.LayerNorm(width[-1]))\n",
        "\n",
        "        self.m = nn.Sequential(*lls)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.m(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1QiHFu62vQKz"
      },
      "outputs": [],
      "source": [
        "class MP_Block(nn.Module):\n",
        "    # L@L.T matrix multiplication graph layer\n",
        "    # Aligns the computation of L@L.T - A with the learned updates\n",
        "    def __init__(self, skip_connections, first, last, edge_features, node_features, global_features, hidden_size, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # first and second aggregation\n",
        "        if \"aggregate\" in kwargs and kwargs[\"aggregate\"] is not None:\n",
        "            aggr = kwargs[\"aggregate\"] if len(kwargs[\"aggregate\"]) == 2 else kwargs[\"aggregate\"] * 2\n",
        "        else:\n",
        "            aggr = [\"mean\", \"sum\"]\n",
        "\n",
        "        act = kwargs[\"activation\"] if \"activation\" in kwargs else \"relu\"\n",
        "\n",
        "        edge_features_in = 1 if first else edge_features\n",
        "        edge_features_out = 1 if last else edge_features\n",
        "\n",
        "        # We use 2 graph nets in order to operate on the upper and lower triangular parts of the matrix\n",
        "        self.l1 = GraphNet(node_features=node_features, edge_features=edge_features_in, global_features=global_features,\n",
        "                           hidden_size=hidden_size, skip_connection=(not first and skip_connections),\n",
        "                           aggregate=aggr[0], activation=act, edge_features_out=edge_features)\n",
        "\n",
        "        self.l2 = GraphNet(node_features=node_features, edge_features=edge_features, global_features=global_features,\n",
        "                           hidden_size=hidden_size, aggregate=aggr[1], activation=act, edge_features_out=edge_features_out)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, global_features):\n",
        "        edge_embedding, node_embeddings, global_features = self.l1(x, edge_index, edge_attr, g=global_features)\n",
        "\n",
        "        # flip row and column indices\n",
        "        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n",
        "        edge_embedding, node_embeddings, global_features = self.l2(node_embeddings, edge_index, edge_embedding, g=global_features)\n",
        "\n",
        "        return edge_embedding, node_embeddings, global_features\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_4QZs900rsR"
      },
      "source": [
        "# **HELPER FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nwNsqPn70qh0"
      },
      "outputs": [],
      "source": [
        "def augment_features(data, skip_rhs=False):\n",
        "    # transform nodes to include more features\n",
        "\n",
        "    if skip_rhs:\n",
        "        # use instead notde position as an input feature!\n",
        "        data.x = torch.arange(data.x.size()[0], device=data.x.device).unsqueeze(1)\n",
        "\n",
        "    data = torch_geometric.transforms.LocalDegreeProfile()(data)\n",
        "\n",
        "    # diagonal dominance and diagonal decay from the paper\n",
        "    row, col = data.edge_index\n",
        "    diag = (row == col)\n",
        "    diag_elem = torch.abs(data.edge_attr[diag])\n",
        "    # remove diagonal elements by setting them to zero\n",
        "    non_diag_elem = data.edge_attr.clone()\n",
        "    non_diag_elem[diag] = 0\n",
        "\n",
        "    row_sums = aggr.SumAggregation()(torch.abs(non_diag_elem), row)\n",
        "    alpha = diag_elem / row_sums\n",
        "    row_dominance_feature = alpha / (alpha + 1)\n",
        "    row_dominance_feature = torch.nan_to_num(row_dominance_feature, nan=1.0)\n",
        "\n",
        "    # compute diagonal decay features\n",
        "    row_max = aggr.MaxAggregation()(torch.abs(non_diag_elem), row)\n",
        "    alpha = diag_elem / row_max\n",
        "    row_decay_feature = alpha / (alpha + 1)\n",
        "    row_decay_feature = torch.nan_to_num(row_decay_feature, nan=1.0)\n",
        "\n",
        "    data.x = torch.cat([data.x, row_dominance_feature, row_decay_feature], dim=1)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "class ToLowerTriangular(torch_geometric.transforms.BaseTransform):\n",
        "    def __init__(self, inplace=False):\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def __call__(self, data, order=None):\n",
        "        if not self.inplace:\n",
        "            data = data.clone()\n",
        "\n",
        "        # TODO: if order is given use that one instead\n",
        "        if order is not None:\n",
        "            raise NotImplementedError(\"Custom ordering not yet implemented...\")\n",
        "\n",
        "        # transform the data into lower triag graph\n",
        "        # this should be a data transformation (maybe?)\n",
        "        rows, cols = data.edge_index[0], data.edge_index[1]\n",
        "        fil = cols <= rows\n",
        "        l_index = data.edge_index[:, fil]\n",
        "        edge_embedding = data.edge_attr[fil]\n",
        "\n",
        "        data.edge_index, data.edge_attr = l_index, edge_embedding\n",
        "        return data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gs0ZVggPzllA"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def validate(model, validation_loader, solve=False, solver=\"cg\"):\n",
        "    model.eval()\n",
        "    acc_loss = 0.0\n",
        "    num_loss = 0\n",
        "    acc_solver_iters = 0.0\n",
        "\n",
        "    for data in validation_loader:\n",
        "        data = data.to(device)\n",
        "        A, b = graph_to_matrix(data)\n",
        "\n",
        "        if solve:\n",
        "            preconditioner = LearnedPreconditioner(data, model)\n",
        "            print(preconditioner)\n",
        "            A_cpu = A.cpu().double()\n",
        "            b_cpu = b.cpu().double()\n",
        "            x0 = None\n",
        "\n",
        "            start = time.time()\n",
        "            if solver == \"cg\":\n",
        "                print(\"Code reaches here\")\n",
        "                iters, x_hat = preconditioned_conjugate_gradient(\n",
        "                    A_cpu, b_cpu, M=None, x0=x0,\n",
        "                    rtol=1e-6, max_iter=1000\n",
        "                )\n",
        "            else:\n",
        "                iters, x_hat = gmres(\n",
        "                    A_cpu, b_cpu, M=preconditioner, x0=x0,\n",
        "                    atol=1e-6, max_iter=1000, left=False\n",
        "                )\n",
        "            acc_solver_iters += len(iters) - 1\n",
        "        else:\n",
        "            output, _, _ = model(data)\n",
        "            # l = frobenius_loss(output, A)\n",
        "            l = loss(data, output, config=\"frobenius\")\n",
        "            acc_loss += l.item()\n",
        "            num_loss += 1\n",
        "\n",
        "    if solve:\n",
        "        print(\"BLABLABLA\")\n",
        "        avg_iters = acc_solver_iters / len(validation_loader)\n",
        "        print(f\"Validation iterations: {avg_iters:.2f}\")\n",
        "        return avg_iters\n",
        "    else:\n",
        "        avg_loss = acc_loss / num_loss\n",
        "        print(f\"Validation loss: {avg_loss:.4f}\")\n",
        "        return avg_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyTWtXYd1Gl0"
      },
      "source": [
        "# **MODEL CONFIGURATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MPu5HMGMHZwG"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"name\": \"experiment_1\",\n",
        "    \"save\": True,\n",
        "    \"seed\": 42,\n",
        "    \"n\": 10000,\n",
        "    \"batch_size\": 1,\n",
        "    \"num_epochs\": 100,\n",
        "    \"dataset\": \"random\",\n",
        "    \"loss\": None,\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"regularizer\": 0.0,\n",
        "    \"scheduler\": False,\n",
        "    \"model\": \"neuralif\",\n",
        "    \"normalize\": False,\n",
        "    \"latent_size\": 8,\n",
        "    \"message_passing_steps\": 3,\n",
        "    \"decode_nodes\": False,\n",
        "    \"normalize_diag\": False,\n",
        "    \"aggregate\": [\"mean\", \"sum\"],\n",
        "    \"activation\": \"relu\",\n",
        "    \"skip_connections\": True,\n",
        "    \"augment_nodes\": False,\n",
        "    \"global_features\": 0,\n",
        "    \"edge_features\": 1,\n",
        "    \"graph_norm\": False,\n",
        "    \"two_hop\": False,\n",
        "    \"num_neighbors\": [15, 10]  # number of neighbours to sample in each hop (GraphSAGE sampling)\n",
        "}\n",
        "\n",
        "# Prepare output folder\n",
        "if config[\"name\"]:\n",
        "    folder = f\"results/{config['name']}\"\n",
        "else:\n",
        "    folder = datetime.datetime.now().strftime(\"results/%Y-%m-%d_%H-%M-%S\")\n",
        "if config[\"save\"]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    save_dict_to_file(config, os.path.join(folder, \"config.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5L6mQaXy1pDs"
      },
      "outputs": [],
      "source": [
        "#NeuralIF imported manually here to avoid using numml\n",
        "\n",
        "class NeuralIF(nn.Module):\n",
        "    # Neural Incomplete factorization\n",
        "    def __init__(self, drop_tol=0, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.global_features = kwargs[\"global_features\"]\n",
        "        self.latent_size = kwargs[\"latent_size\"]\n",
        "        # node features are augmented with local degree profile\n",
        "        self.augment_node_features = kwargs[\"augment_nodes\"]\n",
        "\n",
        "        num_node_features = 8 if self.augment_node_features else 1\n",
        "        message_passing_steps = kwargs[\"message_passing_steps\"]\n",
        "\n",
        "        # edge feature representation in the latent layers\n",
        "        edge_features = kwargs.get(\"edge_features\", 1)\n",
        "\n",
        "        self.skip_connections = kwargs[\"skip_connections\"]\n",
        "\n",
        "        self.mps = torch.nn.ModuleList()\n",
        "        for l in range(message_passing_steps):\n",
        "            # skip connections are added to all layers except the first one\n",
        "            self.mps.append(MP_Block(skip_connections=self.skip_connections,\n",
        "                                     first=l==0,\n",
        "                                     last=l==(message_passing_steps-1),\n",
        "                                     edge_features=edge_features,\n",
        "                                     node_features=num_node_features,\n",
        "                                     global_features=self.global_features,\n",
        "                                     hidden_size=self.latent_size,\n",
        "                                     activation=kwargs[\"activation\"],\n",
        "                                     aggregate=kwargs[\"aggregate\"]))\n",
        "\n",
        "        # node decodings\n",
        "        self.node_decoder = MLP([num_node_features, self.latent_size, 1]) if kwargs[\"decode_nodes\"] else None\n",
        "\n",
        "        # diag-aggregation for normalization of rows\n",
        "        self.normalize_diag = kwargs[\"normalize_diag\"] if \"normalize_diag\" in kwargs else False\n",
        "        self.diag_aggregate = aggr.SumAggregation()\n",
        "\n",
        "        # normalization\n",
        "        self.graph_norm = pyg.norm.GraphNorm(num_node_features) if (\"graph_norm\" in kwargs and kwargs[\"graph_norm\"]) else None\n",
        "\n",
        "        # drop tolerance and additional fill-ins and more sparsity\n",
        "        self.tau = drop_tol\n",
        "        self.two = kwargs.get(\"two_hop\", False)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # ! data could be batched here...(not implemented)\n",
        "\n",
        "        if self.augment_node_features:\n",
        "            data = augment_features(data, skip_rhs=True)\n",
        "\n",
        "        # add additional edges to the data\n",
        "        if self.two:\n",
        "            data = TwoHop()(data)\n",
        "\n",
        "        # * in principle it is possible to integrate reordering here.\n",
        "\n",
        "        data = ToLowerTriangular()(data)\n",
        "\n",
        "        # get the input data\n",
        "        edge_embedding = data.edge_attr\n",
        "        l_index = data.edge_index\n",
        "\n",
        "        if self.graph_norm is not None:\n",
        "            node_embedding = self.graph_norm(data.x, batch=data.batch)\n",
        "        else:\n",
        "            node_embedding = data.x\n",
        "\n",
        "        # copy the input data (only edges of original matrix A)\n",
        "        a_edges = edge_embedding.clone()\n",
        "\n",
        "        if self.global_features > 0:\n",
        "            global_features = torch.zeros((1, self.global_features), device=data.x.device, requires_grad=False)\n",
        "            # feature ideas: nnz, 1-norm, inf-norm col/row var, min/max variability, avg distances to nnz\n",
        "        else:\n",
        "            global_features = None\n",
        "\n",
        "        # compute the output of the network\n",
        "        for i, layer in enumerate(self.mps):\n",
        "            if i != 0 and self.skip_connections:\n",
        "                edge_embedding = torch.cat([edge_embedding, a_edges], dim=1)\n",
        "\n",
        "            edge_embedding, node_embedding, global_features = layer(node_embedding, l_index, edge_embedding, global_features)\n",
        "\n",
        "        # transform the output into a matrix\n",
        "        return self.transform_output_matrix(node_embedding, l_index, edge_embedding, a_edges)\n",
        "\n",
        "    def transform_output_matrix(self, node_x, edge_index, edge_values, a_edges):\n",
        "        # force diagonal to be positive\n",
        "        diag = edge_index[0] == edge_index[1]\n",
        "\n",
        "        # normalize diag such that it has zero residual\n",
        "        if self.normalize_diag:\n",
        "            # copy the diag of matrix A\n",
        "            a_diag = a_edges[diag]\n",
        "\n",
        "            # compute the row norm\n",
        "            square_values = torch.pow(edge_values, 2)\n",
        "            aggregated = self.diag_aggregate(square_values, edge_index[0])\n",
        "\n",
        "            # now, we renormalize the edge values such that they are the square root of the original value...\n",
        "            edge_values = torch.sqrt(a_diag[edge_index[0]]) * edge_values / torch.sqrt(aggregated[edge_index[0]])\n",
        "\n",
        "        else:\n",
        "            # otherwise, just take the edge values as they are...\n",
        "            # but take the square root as it is numerically better\n",
        "            # edge_values[diag] = torch.exp(edge_values[diag])\n",
        "            edge_values[diag] = torch.sqrt(torch.exp(edge_values[diag]))\n",
        "\n",
        "        # node decoder\n",
        "        node_output = self.node_decoder(node_x).squeeze() if self.node_decoder is not None else None\n",
        "\n",
        "        # ! this if should only be activated when the model is in production!!\n",
        "        if torch.is_inference_mode_enabled():\n",
        "\n",
        "            # we can decide to remove small elements during inference from the preconditioner matrix\n",
        "            if self.tau != 0:\n",
        "                small_value = (torch.abs(edge_values) <= self.tau).squeeze()\n",
        "\n",
        "                # small value and not diagonal\n",
        "                elems = torch.logical_and(small_value, torch.logical_not(diag))\n",
        "\n",
        "                # might be able to do this easily!\n",
        "                edge_values[elems] = 0\n",
        "\n",
        "                # remove zeros from the sparse representation\n",
        "                filt = (edge_values != 0).squeeze()\n",
        "                edge_values = edge_values[filt]\n",
        "                edge_index = edge_index[:, filt]\n",
        "\n",
        "            # ! this is the way to go!!\n",
        "            # Doing pytorch -> scipy -> numml is a lot faster than pytorch -> numml on CPU\n",
        "            # On GPU it is faster to go to pytorch -> numml -> CPU\n",
        "\n",
        "            # convert to scipy sparse matrix\n",
        "            # m = to_scipy_sparse_matrix(edge_index, matrix_values)\n",
        "            m = torch.sparse_coo_tensor(edge_index, edge_values.squeeze(),\n",
        "                                        size=(node_x.size()[0], node_x.size()[0]))\n",
        "                                        # type=torch.double)\n",
        "\n",
        "            # produce L and U seperatly\n",
        "            l = sp.SparseCSRTensor(m)\n",
        "            u = sp.SparseCSRTensor(m.T)\n",
        "\n",
        "            return l, u, node_output\n",
        "\n",
        "        else:\n",
        "            # For training and testing (computing regular losses for examples.)\n",
        "            # does not need to be performance optimized!\n",
        "            # use torch sparse directly\n",
        "            t = torch.sparse_coo_tensor(edge_index, edge_values.squeeze(),\n",
        "                                        size=(node_x.size()[0], node_x.size()[0]))\n",
        "\n",
        "            # normalized l1 norm is best computed here!\n",
        "            # l2_nn = torch.linalg.norm(edge_values, ord=2)\n",
        "            l1_penalty = torch.sum(torch.abs(edge_values)) / len(edge_values)\n",
        "\n",
        "            return t, l1_penalty, node_output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms5Os2cPTy1q"
      },
      "source": [
        "# **SETUP**\n",
        "Model instantiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sWXGb14y1MKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27e8fec-f678-44de-b4ee-30df46b84c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 460\n"
          ]
        }
      ],
      "source": [
        "# Seed for reproducibility\n",
        "torch_geometric.seed_everything(config[\"seed\"])\n",
        "\n",
        "# Select model\n",
        "model_args = {k: config[k] for k in [\n",
        "    \"latent_size\", \"message_passing_steps\", \"skip_connections\",\n",
        "    \"augment_nodes\", \"global_features\", \"decode_nodes\",\n",
        "    \"normalize_diag\", \"activation\", \"aggregate\", \"graph_norm\",\n",
        "    \"two_hop\", \"edge_features\", \"normalize\"\n",
        "] if k in config}\n",
        "\n",
        "use_gmres = False\n",
        "if config[\"model\"] in (\"nif\", \"neuralif\", \"inf\"):\n",
        "    model = NeuralIF(**model_args) ##Assign model to be NeuralIF\n",
        "else:\n",
        "    raise ValueError(\"Unknown model type\")\n",
        "\n",
        "model.to(device)\n",
        "print(\"Number of parameters:\", count_parameters(model))\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.5, patience=20\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8176Ece94dQe"
      },
      "source": [
        "# DATALOADER **CLASS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Cwajarhq4bTo"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.sparse import coo_matrix\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "\n",
        "def matrix_to_graph_sparse(A, b):\n",
        "    edge_index = torch.tensor(list(map(lambda x: [x[0], x[1]], zip(A.row, A.col))), dtype=torch.long)\n",
        "    edge_features = torch.tensor(list(map(lambda x: [x], A.data)), dtype=torch.float)\n",
        "    node_features = torch.tensor(list(map(lambda x: [x], b)), dtype=torch.float)\n",
        "\n",
        "    # diag_elements = edge_index[:, 0] == edge_index[:, 1]\n",
        "    # node_features = edge_features[diag_elements]\n",
        "    # node_features = torch.cat((node_features, torch.tensor(list(map(lambda x: [x], b)), dtype=torch.float)), dim=1)\n",
        "\n",
        "    # Embed the information into data object\n",
        "    data = Data(x=node_features, edge_index=edge_index.t().contiguous(), edge_attr=edge_features)\n",
        "    return data\n",
        "\n",
        "\n",
        "def matrix_to_graph(A, b):\n",
        "    return matrix_to_graph_sparse(coo_matrix(A), b)\n",
        "\n",
        "\n",
        "def graph_to_matrix(data, normalize=False):\n",
        "    A = torch.sparse_coo_tensor(data.edge_index, data.edge_attr[:, 0].squeeze(), requires_grad=False)\n",
        "    b = data.x[:, 0].squeeze()\n",
        "\n",
        "    if normalize:\n",
        "        b = b / torch.linalg.norm(b)\n",
        "\n",
        "    return A, b\n",
        "\n",
        "\n",
        "def get_dataloader(dataset, n=0, batch_size=1, spd=True, mode=\"train\", size=None, graph=True):\n",
        "    # Setup datasets\n",
        "\n",
        "    if dataset == \"random\":\n",
        "        print(\"TEST\")\n",
        "        data = FolderDataset(f\"./dataset/train/\", n, size=size, graph=graph) #Note that for our dataset, n must be 10000??\n",
        "        validation = FolderDataset(f\"./dataset/validate/\", n, size=size, graph=graph)\n",
        "    else:\n",
        "        raise NotImplementedError(\"Dataset not implemented, Available: random\")\n",
        "\n",
        "    # Data Loaders\n",
        "    if mode == \"train\":\n",
        "        dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "    else:\n",
        "        dataloader = DataLoader(validation, batch_size=1, shuffle=False)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "class FolderDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, folder, n, graph=True, size=None) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.graph = True\n",
        "        assert self.graph, \"Graph keyword is depracated, only graph=True is supported.\"\n",
        "\n",
        "        if n != 0:\n",
        "            if self.graph:\n",
        "                self.files = list(filter(lambda x: x.split(\"/\")[-1].split('_')[0] == str(n), glob(folder+'*.pt')))\n",
        "            else:\n",
        "                self.files = list(filter(lambda x: x.split(\"/\")[-1].split('_')[0] == str(n), glob(folder+'*.npz')))\n",
        "        else:\n",
        "            file_ending = \"pt\" if self.graph else \"npz\"\n",
        "            self.files = list(glob(folder+f'*.{file_ending}'))\n",
        "\n",
        "        if size is not None:\n",
        "            assert len(self.files) >= size, f\"Only {len(self.files)} files found in {folder} with n={n}\"\n",
        "            self.files = self.files[:size]\n",
        "\n",
        "        if len(self.files) == 0:\n",
        "            raise FileNotFoundError(f\"No files found in {folder} with n={n}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.graph:\n",
        "            g = torch.load(self.files[idx], weights_only=False)\n",
        "\n",
        "        else:\n",
        "            # deprecated...\n",
        "            d = np.load(self.files[idx], allow_pickle=True)\n",
        "            g = matrix_to_graph(d[\"A\"], d[\"b\"])\n",
        "\n",
        "        return g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InGDAScM2VYZ"
      },
      "source": [
        "# **MAIN CODE TO RUN (TRAINING THE MODEL)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "49JcW2wv3nlB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YNDdBrr022Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1b9db0-5a57-47e0-c968-25eb92c8b7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST\n",
            "Data(x=[10000, 1], edge_index=[2, 1005398], edge_attr=[1005398, 1], s=[10000], n=10000)\n",
            "tensor([[0.8808],\n",
            "        [0.6831],\n",
            "        [0.3183],\n",
            "        ...,\n",
            "        [0.7282],\n",
            "        [0.6627],\n",
            "        [0.9138]])\n",
            "tensor([[   0,    0,    0,  ..., 9999, 9999, 9999],\n",
            "        [   0, 1255, 3754,  ..., 4025, 4467, 6623]])\n",
            "33\n",
            "TEST\n"
          ]
        }
      ],
      "source": [
        "# 1. retrieve the FolderDataset object for each of train and validation loader based on .pt files\n",
        "# 2. pass the FolderDataset object into torch.util's DataLoader as the dataset field\n",
        "# 3. return this DataLoader object\n",
        "\n",
        "# the loader below passes train_dataset directly to torch.util's DataLoader class\n",
        "\n",
        "\n",
        "\n",
        "train_loader = get_dataloader(config[\"dataset\"], config[\"n\"], config[\"batch_size\"],\n",
        "                                  spd=not gmres, mode=\"train\")\n",
        "\n",
        "print(train_loader.dataset[0])\n",
        "print(train_loader.dataset[0].x)\n",
        "print(train_loader.dataset[0].edge_index)\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "validation_loader = get_dataloader(config[\"dataset\"], config[\"n\"], 1, spd=(not gmres), mode=\"val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5UPVxNF1q22",
        "outputId": "535b5dc0-882f-4146-8d7e-0455741f91b9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 ‚Äî loss: 394.4080, time: 48.8s\n",
            "Epoch 2 ‚Äî loss: 393.4740, time: 47.9s\n",
            "Epoch 3 ‚Äî loss: 392.4386, time: 48.4s\n",
            "Epoch 4 ‚Äî loss: 391.9327, time: 48.1s\n",
            "Epoch 5 ‚Äî loss: 391.6303, time: 48.3s\n",
            "Epoch 6 ‚Äî loss: 391.1181, time: 48.9s\n",
            "<__main__.LearnedPreconditioner object at 0x7994a4a8ce50>\n",
            "Code reaches here\n",
            "<__main__.LearnedPreconditioner object at 0x7994a4bf9910>\n",
            "Code reaches here\n",
            "<__main__.LearnedPreconditioner object at 0x7994a4b79450>\n",
            "Code reaches here\n",
            "<__main__.LearnedPreconditioner object at 0x7994a4dc9a10>\n",
            "Code reaches here\n",
            "<__main__.LearnedPreconditioner object at 0x7994a51d8550>\n",
            "Code reaches here\n",
            "<__main__.LearnedPreconditioner object at 0x7994a51d9190>\n",
            "Code reaches here\n",
            "<__main__.LearnedPreconditioner object at 0x7994a4d07010>\n",
            "Code reaches here\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.utils import add_self_loops\n",
        "\n",
        "# training loop\n",
        "best_val = float(\"inf\")\n",
        "logger = TrainResults(folder)\n",
        "total_it = 0\n",
        "\n",
        "for epoch in range(config[\"num_epochs\"]):\n",
        "    running_loss = 0.0\n",
        "    start_epoch = time.perf_counter()\n",
        "\n",
        "    for data in train_loader:\n",
        "        total_it += 1\n",
        "        model.train()\n",
        "\n",
        "        start = time.perf_counter()\n",
        "        data = data.to(device)\n",
        "\n",
        "        ### resolving the unmatching dimension bug for NeighborSampler class\n",
        "        # 1) override n properly\n",
        "        data.n = int(data.x.size(0))\n",
        "\n",
        "        # 2) add self-loops so each node has at least one incoming edge\n",
        "        data.edge_index, data.edge_attr = add_self_loops(\n",
        "            data.edge_index,\n",
        "            data.edge_attr,\n",
        "            fill_value=0.0,\n",
        "            num_nodes=data.n\n",
        "        )\n",
        "        ###\n",
        "\n",
        "        # print(f\"Input training data to the model is {data}\")\n",
        "        output, reg, _ = model(data)\n",
        "        # print(f\"Output from the model is {output} and reg term is {reg}\")\n",
        "\n",
        "        l = loss(output, data, c=reg, config=config[\"loss\"])\n",
        "        l.backward()\n",
        "\n",
        "        # gradient clipping or manual norm\n",
        "        if config[\"gradient_clipping\"]:\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                model.parameters(), config[\"gradient_clipping\"]\n",
        "            )\n",
        "        else:\n",
        "            total_norm = sum(\n",
        "                p.grad.detach().data.norm(2).item() ** 2\n",
        "                for p in model.parameters() if p.grad is not None\n",
        "            )\n",
        "            grad_norm = (total_norm ** 0.5) / config[\"batch_size\"]\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += l.item()\n",
        "        logger.log(l.item(), grad_norm, time.perf_counter() - start)\n",
        "\n",
        "        # periodic validation\n",
        "        if total_it % 200 == 0:\n",
        "            use_gmres = False\n",
        "            val_metric = validate(\n",
        "                model, validation_loader, solve=True,\n",
        "                solver=\"gmres\" if use_gmres else \"cg\"\n",
        "            )\n",
        "            logger.log_val(None, val_metric)\n",
        "            print(val_metric)\n",
        "            if val_metric < best_val:\n",
        "                best_val = val_metric\n",
        "                if config[\"save\"]:\n",
        "                    torch.save(model.state_dict(), f\"{folder}/best_model.pt\")\n",
        "\n",
        "    epoch_time = time.perf_counter() - start_epoch\n",
        "    print(f\"Epoch {epoch+1} ‚Äî loss: {running_loss/len(train_loader):.4f}, time: {epoch_time:.1f}s\")\n",
        "    if config[\"save\"]:\n",
        "        torch.save(model.state_dict(), f\"{folder}/model_epoch{epoch+1}.pt\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aHDcK8D8Cz4"
      },
      "source": [
        "# **VALIDATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GFa8ZBGYft_S"
      },
      "outputs": [],
      "source": [
        "class Preconditioner:\n",
        "    def __init__(self, A, **kwargs):\n",
        "        self.breakdown = False\n",
        "        self.nnz = 0\n",
        "        self.time = 0\n",
        "        self.n = kwargs.get(\"n\", 0)\n",
        "\n",
        "    def timed_setup(self, A, **kwargs):\n",
        "        start = time_function()\n",
        "        self.setup(A, **kwargs)\n",
        "        stop = time_function()\n",
        "        self.time = stop - start\n",
        "\n",
        "    def get_inverse(self):\n",
        "        ones = torch.ones(self.n)\n",
        "        offset = torch.zeros(1).to(torch.int64)\n",
        "\n",
        "        I = torch.sparse.spdiags(ones, offset, (self.n, self.n))\n",
        "        I = I.to(torch.float64)\n",
        "\n",
        "        return I\n",
        "\n",
        "    def get_p_matrix(self):\n",
        "        return self.get_inverse()\n",
        "\n",
        "    def check_breakdown(self, P):\n",
        "        if np.isnan(np.min(P)):\n",
        "            self.breakdown = True\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return x\n",
        "\n",
        "time_function = lambda: time.perf_counter()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MDfGjIrNgqjC"
      },
      "outputs": [],
      "source": [
        "class LearnedPreconditioner(Preconditioner):\n",
        "    def __init__(self, data, model, **kwargs):\n",
        "        super().__init__(data, **kwargs)\n",
        "\n",
        "        self.model = model\n",
        "        self.spd = isinstance(model, NeuralIF)\n",
        "\n",
        "        self.timed_setup(data, **kwargs)\n",
        "\n",
        "        if self.spd:\n",
        "            self.nnz = self.L._nnz()\n",
        "        else:\n",
        "            self.nnz = self.L._nnz() + self.U._nnz() - data.x.shape[0]\n",
        "\n",
        "    def setup(self, data, **kwargs):\n",
        "        L, U, _ = self.model(data)\n",
        "\n",
        "        self.L = L.to(\"cuda\")\n",
        "        self.U = U.to(\"cuda\")\n",
        "\n",
        "    def get_inverse(self):\n",
        "        L_inv = torch.inverse(self.L.to_dense())\n",
        "        U_inv = torch.inverse(self.U.to_dense())\n",
        "\n",
        "        return U_inv@L_inv\n",
        "\n",
        "    def get_p_matrix(self):\n",
        "        return self.L@self.U\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # return fb_solve(self.L, self.U, x, unit_upper=not self.spd)\n",
        "        P = self.get_p_matrix()  # P = L @ U\n",
        "        return torch.linalg.solve(P, x)\n",
        "\n",
        "\n",
        "def fb_solve(L, U, r, unit_lower=False, unit_upper=False):\n",
        "    y = L.solve_triangular(upper=False, unit=unit_lower, b=r)\n",
        "    z = U.solve_triangular(upper=True, unit=unit_upper, b=y)\n",
        "    return z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lqfyxYC8ZVR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}