{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scalable GNN–Based Preconditioners for Conjugate Gradient Methods\n",
        "**Authors: Nicholas Tan Yun Yu, Low Jun Yu, Yuhan Wu**\n",
        "\n",
        "This project was inspired by [NeuralIF](https://arxiv.org/abs/2305.16368).\n",
        "\n",
        "**Summary**: The authors come up with a novel message-passing GNN block that is used by the network to predict efficient preconditioners to solve sparse linear systems. These preconditioners are tested using the preconditioned conjugate gradient (CG) method, which make the algorithm converge faster than other state-of-the-art preconditioners.\n",
        "\n",
        "**Motivation**: Modern data-driven and physics-based applications frequently force us to deal with dense matrices. Therefore, we hope to show that the message-passing GNN block can learn effective preconditioners for these scaled up fields. An example of a machine learning problem that could benefit from this is Gaussian Processes, which makes use of a dense kernel function as such: (some image)\n",
        "\n",
        "**The problem**: Scaling the problem to dense matrices is nontrivial. The Coates graph representation has 1 node per row/column, and one edge only for each nonzero entry in A. For a dense n*n matrix, that graph becomes complete – with n^2 edges – so both memory and compute blow up to O(n^2).\n",
        "\n",
        "**Research direction**: Implement an edge-regression GNN that can work on dense matrices. We can achieve this using sampling techniques such as GraphSAGE and Cluster-GCN."
      ],
      "metadata": {
        "id": "J_CMa5FedgDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installation & Setup"
      ],
      "metadata": {
        "id": "XrqVh2BF7LhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load files from google drive"
      ],
      "metadata": {
        "id": "-4MVBD1eXd8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSuii7-phJYZ",
        "outputId": "956cc283-ce79-45ed-bae6-96e223dea91d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add directory to python's path\n",
        "# This directory path should lead straight to the root of the project\n",
        "# Ensure that the project's root directory has the folders \"krylov\", \"apps\" and \"neuralif\"\n",
        "#   that has the files contained in https://github.com/paulhausner/neural-incomplete-factorization/tree/main\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CS4350/project/')"
      ],
      "metadata": {
        "id": "tbuq9axkgIj_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package installation"
      ],
      "metadata": {
        "id": "ehpIKqQaX36-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q torch_geometric"
      ],
      "metadata": {
        "id": "WuLYpuGUDMoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e49c7f8-2f68-44bf-f4fa-ab4082f51248"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ilupp\n",
            "  Downloading ilupp-1.0.2.tar.gz (155 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.11/dist-packages (from ilupp) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ilupp) (1.15.3)\n",
            "Building wheels for collected packages: ilupp\n",
            "  Building wheel for ilupp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ilupp: filename=ilupp-1.0.2-cp311-cp311-linux_x86_64.whl size=3237621 sha256=c0ee1a6b4ea952ac3a9d56aa076908097b758e3284f7689875c76fe3f3d335d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/29/86/ee4ba827a16c7450e9750424fd645ce86fc0d958fadf3e9f9c\n",
            "Successfully built ilupp\n",
            "Installing collected packages: ilupp\n",
            "Successfully installed ilupp-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "HgiuVFCFX9Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "import pprint\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg\n",
        "from torch_geometric.nn import aggr\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from scipy.sparse import tril, coo_matrix\n",
        "\n",
        "from apps.data import get_dataloader, graph_to_matrix, matrix_to_graph\n",
        "from neuralif.utils import (\n",
        "    count_parameters, save_dict_to_file,\n",
        "    condition_number, eigenval_distribution, gershgorin_norm,\n",
        "    TwoHop\n",
        ")\n",
        "from neuralif.logger import TrainResults, TestResults\n",
        "from neuralif.loss import loss\n",
        "\n",
        "from krylov.cg import preconditioned_conjugate_gradient\n",
        "from krylov.gmres import gmres\n",
        "\n",
        "# import from self-curated numml file\n",
        "from numml import SparseCSRTensor"
      ],
      "metadata": {
        "id": "c3uK7LjaQoMt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "52722b90-7dc0-4f6f-a787-26fc6768209b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numml.sparse'; 'numml' is not a package",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3fd0d0f468a0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkrylov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreconditioned_conjugate_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkrylov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgmres\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgmres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkrylov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreconditioner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLearnedPreconditioner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# import from self-curated numml file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/CS4350/project/krylov/preconditioner.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuralif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_sparse_to_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneuralif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeuralIF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/CS4350/project/neuralif/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpyg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numml.sparse'; 'numml' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set GPU"
      ],
      "metadata": {
        "id": "1BzKAAbyYE59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDfXtM3xQzwJ",
        "outputId": "696cffa5-fda4-441b-d8f4-2405b2b64a75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset generation"
      ],
      "metadata": {
        "id": "zmYSP8cAZFaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "cA9OMUsXaQKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sparse_random(n, alpha=1e-4, random_state=0, sol=False, ood=False):\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    if alpha is None:\n",
        "        alpha = rng.uniform(1e-4, 1e-2)\n",
        "    sparsity = 10e-4  # this is 1% sparsity for n = 10 000\n",
        "\n",
        "    if ood:\n",
        "        factor = rng.uniform(0.22, 2.2)\n",
        "        sparsity *= factor\n",
        "\n",
        "    nnz = int(sparsity * n ** 2)\n",
        "    rows = [rng.randint(0, n) for _ in range(nnz)]\n",
        "    cols = [rng.randint(0, n) for _ in range(nnz)]\n",
        "    uniques = set(zip(rows, cols))\n",
        "    rows, cols = zip(*uniques)\n",
        "    vals = rng.normal(0, 1, size=len(cols))\n",
        "\n",
        "    M = coo_matrix((vals, (rows, cols)), shape=(n, n))\n",
        "    I = scipy.sparse.identity(n)\n",
        "    A = (M @ M.T) + alpha * I # create spd matrix\n",
        "    print(f\"Generated matrix with {100 * (A.nnz / n**2):.2f}% non-zeros ({A.nnz} entries)\")\n",
        "\n",
        "    b = rng.uniform(0, 1, size=n)\n",
        "    x = None\n",
        "    if sol:\n",
        "        x, _ = scipy.sparse.linalg.cg(A, b)\n",
        "    return A, x, b\n",
        "\n",
        "def create_dataset(n, samples, alpha=1e-2, graph=True, rs=0, mode='train', solution=False):\n",
        "    if mode != 'train' and rs == 0:\n",
        "        raise ValueError('`rs` must be non-zero for val/test to avoid overlap')\n",
        "\n",
        "    print(f\"Creating {samples} samples for '{mode}' set (n={n})\")\n",
        "    for sam in range(samples):\n",
        "        A, x, b = generate_sparse_random(\n",
        "            n, alpha=alpha, random_state=rs + sam,\n",
        "            sol=solution, ood=(mode == \"test_ood\")\n",
        "        )\n",
        "        if graph:\n",
        "            g = matrix_to_graph(A, b)\n",
        "            if x is not None:\n",
        "                g.s = torch.tensor(x, dtype=torch.float)\n",
        "            g.n = n\n",
        "            torch.save(g, f'./data/Random/{mode}/{n}_{sam}.pt')\n",
        "        else:\n",
        "            scipy.sparse.save_npz(f'./data/Random/{mode}/{n}_{sam}.npz', A)\n",
        "            np.savez(f'./data/Random/{mode}/{n}_{sam}.npz', A=A, b=b, x=x)\n"
      ],
      "metadata": {
        "id": "JKMq525PZEId"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Train, Validation and Test datasets"
      ],
      "metadata": {
        "id": "2Coq9OGHdUm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure target folders exist\n",
        "for split in ['train', 'val', 'test']:\n",
        "    os.makedirs(f'./data/Random/{split}', exist_ok=True)\n",
        "\n",
        "# parameters\n",
        "n = 10_00\n",
        "alpha = 1e-4\n",
        "\n",
        "# generate\n",
        "create_dataset(n, samples=100, alpha=alpha, mode='train', rs=0, graph=True, solution=True)\n",
        "create_dataset(n, samples=5, alpha=alpha, mode='val', rs=10000, graph=True, solution=False)\n",
        "create_dataset(n, samples=20, alpha=alpha, mode='test', rs=103600, graph=True, solution=False)\n"
      ],
      "metadata": {
        "id": "lWJ7E9ZEaCQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca723355-07f3-45e6-daaf-840d0a67dbcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating 100 samples for 'train' set (n=1000)\n",
            "Generated matrix with 0.21% non-zeros (2078 entries)\n",
            "Generated matrix with 0.21% non-zeros (2072 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1978 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (1962 entries)\n",
            "Generated matrix with 0.20% non-zeros (2032 entries)\n",
            "Generated matrix with 0.21% non-zeros (2066 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (2008 entries)\n",
            "Generated matrix with 0.20% non-zeros (2018 entries)\n",
            "Generated matrix with 0.20% non-zeros (2040 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (2010 entries)\n",
            "Generated matrix with 0.20% non-zeros (2006 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.19% non-zeros (1918 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1964 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1962 entries)\n",
            "Generated matrix with 0.20% non-zeros (2042 entries)\n",
            "Generated matrix with 0.20% non-zeros (2010 entries)\n",
            "Generated matrix with 0.20% non-zeros (1982 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n",
            "Generated matrix with 0.20% non-zeros (1988 entries)\n",
            "Generated matrix with 0.21% non-zeros (2072 entries)\n",
            "Generated matrix with 0.19% non-zeros (1950 entries)\n",
            "Generated matrix with 0.20% non-zeros (1960 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1974 entries)\n",
            "Generated matrix with 0.20% non-zeros (1984 entries)\n",
            "Generated matrix with 0.19% non-zeros (1904 entries)\n",
            "Generated matrix with 0.20% non-zeros (2044 entries)\n",
            "Generated matrix with 0.20% non-zeros (2044 entries)\n",
            "Generated matrix with 0.20% non-zeros (1976 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (2008 entries)\n",
            "Generated matrix with 0.21% non-zeros (2108 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (1974 entries)\n",
            "Generated matrix with 0.19% non-zeros (1944 entries)\n",
            "Generated matrix with 0.20% non-zeros (2006 entries)\n",
            "Generated matrix with 0.20% non-zeros (1982 entries)\n",
            "Generated matrix with 0.21% non-zeros (2086 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (1988 entries)\n",
            "Generated matrix with 0.21% non-zeros (2054 entries)\n",
            "Generated matrix with 0.20% non-zeros (2018 entries)\n",
            "Generated matrix with 0.20% non-zeros (2000 entries)\n",
            "Generated matrix with 0.20% non-zeros (2018 entries)\n",
            "Generated matrix with 0.20% non-zeros (2026 entries)\n",
            "Generated matrix with 0.20% non-zeros (1974 entries)\n",
            "Generated matrix with 0.19% non-zeros (1938 entries)\n",
            "Generated matrix with 0.21% non-zeros (2062 entries)\n",
            "Generated matrix with 0.19% non-zeros (1948 entries)\n",
            "Generated matrix with 0.20% non-zeros (2008 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (2000 entries)\n",
            "Generated matrix with 0.20% non-zeros (1964 entries)\n",
            "Generated matrix with 0.20% non-zeros (1972 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (2002 entries)\n",
            "Generated matrix with 0.20% non-zeros (1984 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n",
            "Generated matrix with 0.21% non-zeros (2050 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2012 entries)\n",
            "Generated matrix with 0.19% non-zeros (1936 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (2026 entries)\n",
            "Generated matrix with 0.20% non-zeros (1958 entries)\n",
            "Generated matrix with 0.21% non-zeros (2070 entries)\n",
            "Generated matrix with 0.20% non-zeros (2012 entries)\n",
            "Generated matrix with 0.20% non-zeros (1976 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2012 entries)\n",
            "Generated matrix with 0.20% non-zeros (2022 entries)\n",
            "Generated matrix with 0.20% non-zeros (2004 entries)\n",
            "Generated matrix with 0.20% non-zeros (2028 entries)\n",
            "Generated matrix with 0.20% non-zeros (1958 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2034 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.19% non-zeros (1932 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2010 entries)\n",
            "Generated matrix with 0.20% non-zeros (1956 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (2030 entries)\n",
            "Generated matrix with 0.20% non-zeros (1964 entries)\n",
            "Generated matrix with 0.20% non-zeros (2032 entries)\n",
            "Generated matrix with 0.20% non-zeros (1960 entries)\n",
            "Creating 5 samples for 'val' set (n=1000)\n",
            "Generated matrix with 0.19% non-zeros (1936 entries)\n",
            "Generated matrix with 0.20% non-zeros (2042 entries)\n",
            "Generated matrix with 0.21% non-zeros (2090 entries)\n",
            "Generated matrix with 0.19% non-zeros (1936 entries)\n",
            "Generated matrix with 0.21% non-zeros (2074 entries)\n",
            "Creating 20 samples for 'test' set (n=1000)\n",
            "Generated matrix with 0.20% non-zeros (2026 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.21% non-zeros (2114 entries)\n",
            "Generated matrix with 0.20% non-zeros (2044 entries)\n",
            "Generated matrix with 0.20% non-zeros (2020 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (1978 entries)\n",
            "Generated matrix with 0.19% non-zeros (1900 entries)\n",
            "Generated matrix with 0.20% non-zeros (2020 entries)\n",
            "Generated matrix with 0.20% non-zeros (2004 entries)\n",
            "Generated matrix with 0.20% non-zeros (1952 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n",
            "Generated matrix with 0.19% non-zeros (1926 entries)\n",
            "Generated matrix with 0.20% non-zeros (2000 entries)\n",
            "Generated matrix with 0.19% non-zeros (1924 entries)\n",
            "Generated matrix with 0.20% non-zeros (1988 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1982 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Models"
      ],
      "metadata": {
        "id": "4Jmnl78bbJzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper classes and functions"
      ],
      "metadata": {
        "id": "uVkV8IKb4uV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "#          Layers          #\n",
        "############################\n",
        "class GraphNet(nn.Module):\n",
        "    # Follows roughly the outline of torch_geometric.nn.MessagePassing()\n",
        "    # As shown in https://github.com/deepmind/graph_nets\n",
        "    # Here is a helpful python implementation:\n",
        "    # https://github.com/NVIDIA/GraphQSat/blob/main/gqsat/models.py\n",
        "    # Also allows multirgaph GNN via edge_2_features\n",
        "    def __init__(self, node_features, edge_features, global_features=0, hidden_size=0,\n",
        "                 aggregate=\"mean\", activation=\"relu\", skip_connection=False, edge_features_out=None):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # different aggregation functions\n",
        "        if aggregate == \"sum\":\n",
        "            self.aggregate = aggr.SumAggregation()\n",
        "        elif aggregate == \"mean\":\n",
        "            self.aggregate = aggr.MeanAggregation()\n",
        "        elif aggregate == \"max\":\n",
        "            self.aggregate = aggr.MaxAggregation()\n",
        "        elif aggregate == \"softmax\":\n",
        "            self.aggregate = aggr.SoftmaxAggregation(learn=True)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Aggregation '{aggregate}' not implemented\")\n",
        "\n",
        "        self.global_aggregate = aggr.MeanAggregation()\n",
        "\n",
        "        add_edge_fs = 1 if skip_connection else 0\n",
        "        edge_features_out = edge_features if edge_features_out is None else edge_features_out\n",
        "\n",
        "        # Graph Net Blocks (see https://arxiv.org/pdf/1806.01261.pdf)\n",
        "        self.edge_block = MLP([global_features + (edge_features + add_edge_fs) + (2 * node_features),\n",
        "                               hidden_size,\n",
        "                               edge_features_out],\n",
        "                              activation=activation)\n",
        "\n",
        "        self.node_block = MLP([global_features + edge_features_out + node_features,\n",
        "                               hidden_size,\n",
        "                               node_features],\n",
        "                              activation=activation)\n",
        "\n",
        "        # optional set of blocks for global GNN\n",
        "        self.global_block = None\n",
        "        if global_features > 0:\n",
        "            self.global_block = MLP([edge_features_out + node_features + global_features,\n",
        "                                     hidden_size,\n",
        "                                     global_features],\n",
        "                                    activation=activation)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, g=None):\n",
        "        row, col = edge_index\n",
        "\n",
        "        if self.global_block is not None:\n",
        "            assert g is not None, \"Need global features for global block\"\n",
        "\n",
        "            # run the edge update and aggregate features\n",
        "            edge_embedding = self.edge_block(torch.cat([torch.ones(x[row].shape[0], 1, device=x.device) * g,\n",
        "                                                        x[row], x[col], edge_attr], dim=1))\n",
        "            aggregation = self.aggregate(edge_embedding, row)\n",
        "\n",
        "\n",
        "            agg_features = torch.cat([torch.ones(x.shape[0], 1, device=x.device) * g, x, aggregation], dim=1)\n",
        "            node_embeddings = self.node_block(agg_features)\n",
        "\n",
        "            # aggregate over all edges and nodes (always mean)\n",
        "            mp_global_aggr = g\n",
        "            edge_aggregation_global = self.global_aggregate(edge_embedding)\n",
        "            node_aggregation_global = self.global_aggregate(node_embeddings)\n",
        "\n",
        "            # compute the new global embedding\n",
        "            # the old global feature is part of mp_global_aggr\n",
        "            global_embeddings = self.global_block(torch.cat([node_aggregation_global,\n",
        "                                                             edge_aggregation_global,\n",
        "                                                             mp_global_aggr], dim=1))\n",
        "\n",
        "            return edge_embedding, node_embeddings, global_embeddings\n",
        "\n",
        "        else:\n",
        "            # update edge features and aggregate\n",
        "            edge_embedding = self.edge_block(torch.cat([x[row], x[col], edge_attr], dim=1))\n",
        "            aggregation = self.aggregate(edge_embedding, row)\n",
        "            agg_features = torch.cat([x, aggregation], dim=1)\n",
        "            # update node features\n",
        "            node_embeddings = self.node_block(agg_features)\n",
        "            return edge_embedding, node_embeddings, None\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, width, layer_norm=False, activation=\"relu\", activate_final=False):\n",
        "        super().__init__()\n",
        "        width = list(filter(lambda x: x > 0, width))\n",
        "        assert len(width) >= 2, \"Need at least one layer in the network!\"\n",
        "\n",
        "        lls = nn.ModuleList()\n",
        "        for k in range(len(width)-1):\n",
        "            lls.append(nn.Linear(width[k], width[k+1], bias=True))\n",
        "            if k != (len(width)-2) or activate_final:\n",
        "                if activation == \"relu\":\n",
        "                    lls.append(nn.ReLU())\n",
        "                elif activation == \"tanh\":\n",
        "                    lls.append(nn.Tanh())\n",
        "                elif activation == \"leakyrelu\":\n",
        "                    lls.append(nn.LeakyReLU())\n",
        "                elif activation == \"sigmoid\":\n",
        "                    lls.append(nn.Sigmoid())\n",
        "                else:\n",
        "                    raise NotImplementedError(f\"Activation '{activation}' not implemented\")\n",
        "\n",
        "        if layer_norm:\n",
        "            lls.append(nn.LayerNorm(width[-1]))\n",
        "\n",
        "        self.m = nn.Sequential(*lls)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.m(x)\n",
        "\n",
        "\n",
        "class MP_Block(nn.Module):\n",
        "    # L@L.T matrix multiplication graph layer\n",
        "    # Aligns the computation of L@L.T - A with the learned updates\n",
        "    def __init__(self, skip_connections, first, last, edge_features, node_features, global_features, hidden_size, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # first and second aggregation\n",
        "        if \"aggregate\" in kwargs and kwargs[\"aggregate\"] is not None:\n",
        "            aggr = kwargs[\"aggregate\"] if len(kwargs[\"aggregate\"]) == 2 else kwargs[\"aggregate\"] * 2\n",
        "        else:\n",
        "            aggr = [\"mean\", \"sum\"]\n",
        "\n",
        "        act = kwargs[\"activation\"] if \"activation\" in kwargs else \"relu\"\n",
        "\n",
        "        edge_features_in = 1 if first else edge_features\n",
        "        edge_features_out = 1 if last else edge_features\n",
        "\n",
        "        # We use 2 graph nets in order to operate on the upper and lower triangular parts of the matrix\n",
        "        self.l1 = GraphNet(node_features=node_features, edge_features=edge_features_in, global_features=global_features,\n",
        "                           hidden_size=hidden_size, skip_connection=(not first and skip_connections),\n",
        "                           aggregate=aggr[0], activation=act, edge_features_out=edge_features)\n",
        "\n",
        "        self.l2 = GraphNet(node_features=node_features, edge_features=edge_features, global_features=global_features,\n",
        "                           hidden_size=hidden_size, aggregate=aggr[1], activation=act, edge_features_out=edge_features_out)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, global_features):\n",
        "        edge_embedding, node_embeddings, global_features = self.l1(x, edge_index, edge_attr, g=global_features)\n",
        "\n",
        "        # flip row and column indices\n",
        "        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n",
        "        edge_embedding, node_embeddings, global_features = self.l2(node_embeddings, edge_index, edge_embedding, g=global_features)\n",
        "\n",
        "        return edge_embedding, node_embeddings, global_features\n",
        "\n",
        "############################\n",
        "#         HELPERS          #\n",
        "############################\n",
        "def augment_features(data, skip_rhs=False):\n",
        "    # transform nodes to include more features\n",
        "\n",
        "    if skip_rhs:\n",
        "        # use instead notde position as an input feature!\n",
        "        data.x = torch.arange(data.x.size()[0], device=data.x.device).unsqueeze(1)\n",
        "\n",
        "    data = torch_geometric.transforms.LocalDegreeProfile()(data)\n",
        "\n",
        "    # diagonal dominance and diagonal decay from the paper\n",
        "    row, col = data.edge_index\n",
        "    diag = (row == col)\n",
        "    diag_elem = torch.abs(data.edge_attr[diag])\n",
        "    # remove diagonal elements by setting them to zero\n",
        "    non_diag_elem = data.edge_attr.clone()\n",
        "    non_diag_elem[diag] = 0\n",
        "\n",
        "    row_sums = aggr.SumAggregation()(torch.abs(non_diag_elem), row)\n",
        "    alpha = diag_elem / row_sums\n",
        "    row_dominance_feature = alpha / (alpha + 1)\n",
        "    row_dominance_feature = torch.nan_to_num(row_dominance_feature, nan=1.0)\n",
        "\n",
        "    # compute diagonal decay features\n",
        "    row_max = aggr.MaxAggregation()(torch.abs(non_diag_elem), row)\n",
        "    alpha = diag_elem / row_max\n",
        "    row_decay_feature = alpha / (alpha + 1)\n",
        "    row_decay_feature = torch.nan_to_num(row_decay_feature, nan=1.0)\n",
        "\n",
        "    data.x = torch.cat([data.x, row_dominance_feature, row_decay_feature], dim=1)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "class ToLowerTriangular(torch_geometric.transforms.BaseTransform):\n",
        "    def __init__(self, inplace=False):\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def __call__(self, data, order=None):\n",
        "        if not self.inplace:\n",
        "            data = data.clone()\n",
        "\n",
        "        # TODO: if order is given use that one instead\n",
        "        if order is not None:\n",
        "            raise NotImplementedError(\"Custom ordering not yet implemented...\")\n",
        "\n",
        "        # transform the data into lower triag graph\n",
        "        # this should be a data transformation (maybe?)\n",
        "        rows, cols = data.edge_index[0], data.edge_index[1]\n",
        "        fil = cols <= rows\n",
        "        l_index = data.edge_index[:, fil]\n",
        "        edge_embedding = data.edge_attr[fil]\n",
        "\n",
        "        data.edge_index, data.edge_attr = l_index, edge_embedding\n",
        "        return data"
      ],
      "metadata": {
        "id": "tB5GbXVa4xrJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Preconditioner:\n",
        "    def __init__(self, A, **kwargs):\n",
        "        self.breakdown = False\n",
        "        self.nnz = 0\n",
        "        self.time = 0\n",
        "        self.n = kwargs.get(\"n\", 0)\n",
        "\n",
        "    def timed_setup(self, A, **kwargs):\n",
        "        start = time_function()\n",
        "        self.setup(A, **kwargs)\n",
        "        stop = time_function()\n",
        "        self.time = stop - start\n",
        "\n",
        "    def get_inverse(self):\n",
        "        ones = torch.ones(self.n)\n",
        "        offset = torch.zeros(1).to(torch.int64)\n",
        "\n",
        "        I = torch.sparse.spdiags(ones, offset, (self.n, self.n))\n",
        "        I = I.to(torch.float64)\n",
        "\n",
        "        return I\n",
        "\n",
        "    def get_p_matrix(self):\n",
        "        return self.get_inverse()\n",
        "\n",
        "    def check_breakdown(self, P):\n",
        "        if np.isnan(np.min(P)):\n",
        "            self.breakdown = True\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return x\n",
        "\n",
        "class LearnedPreconditioner(Preconditioner):\n",
        "    def __init__(self, data, model, **kwargs):\n",
        "        super().__init__(data, **kwargs)\n",
        "\n",
        "        self.model = model\n",
        "        self.spd = isinstance(model, NeuralIF)\n",
        "\n",
        "        self.timed_setup(data, **kwargs)\n",
        "\n",
        "        if self.spd:\n",
        "            self.nnz = self.L.nnz\n",
        "        else:\n",
        "            self.nnz = self.L.nnz + self.U.nnz - data.x.shape[0]\n",
        "\n",
        "    def setup(self, data, **kwargs):\n",
        "        L, U, _ = self.model(data)\n",
        "\n",
        "        self.L = L.to(\"cpu\").to(torch.float64)\n",
        "        self.U = U.to(\"cpu\").to(torch.float64)\n",
        "\n",
        "    def get_inverse(self):\n",
        "        L_inv = torch.inverse(self.L.to_dense())\n",
        "        U_inv = torch.inverse(self.U.to_dense())\n",
        "\n",
        "        return U_inv@L_inv\n",
        "\n",
        "    def get_p_matrix(self):\n",
        "        return self.L@self.U\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return fb_solve(self.L, self.U, x, unit_upper=not self.spd)\n",
        "\n",
        "\n",
        "def fb_solve(L, U, r, unit_lower=False, unit_upper=False):\n",
        "    y = L.solve_triangular(upper=False, unit=unit_lower, b=r)\n",
        "    z = U.solve_triangular(upper=True, unit=unit_upper, b=y)\n",
        "    return z\n",
        "\n",
        "time_function = lambda: time.perf_counter()"
      ],
      "metadata": {
        "id": "bx6j4iRY-XYl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions\n",
        "@torch.no_grad()\n",
        "def validate(model, validation_loader, solve=False, solver=\"cg\"):\n",
        "    model.eval()\n",
        "    acc_loss = 0.0\n",
        "    num_loss = 0\n",
        "    acc_solver_iters = 0.0\n",
        "\n",
        "    for data in validation_loader:\n",
        "        data = data.to(device)\n",
        "        A, b = graph_to_matrix(data)\n",
        "\n",
        "        if solve:\n",
        "            preconditioner = LearnedPreconditioner(data, model)\n",
        "            A_cpu = A.cpu().double()\n",
        "            b_cpu = b.cpu().double()\n",
        "            x0 = None\n",
        "\n",
        "            start = time.time()\n",
        "            if solver == \"cg\":\n",
        "                iters, x_hat = preconditioned_conjugate_gradient(\n",
        "                    A_cpu, b_cpu, M=preconditioner, x0=x0,\n",
        "                    rtol=1e-6, max_iter=1000\n",
        "                )\n",
        "            else:\n",
        "                iters, x_hat = gmres(\n",
        "                    A_cpu, b_cpu, M=preconditioner, x0=x0,\n",
        "                    atol=1e-6, max_iter=1000, left=False\n",
        "                )\n",
        "            acc_solver_iters += len(iters) - 1\n",
        "        else:\n",
        "            output, _, _ = model(data)\n",
        "            # l = frobenius_loss(output, A)\n",
        "            l = loss(data, output, config=\"frobenius\")\n",
        "            acc_loss += l.item()\n",
        "            num_loss += 1\n",
        "\n",
        "    if solve:\n",
        "        avg_iters = acc_solver_iters / len(validation_loader)\n",
        "        print(f\"Validation iterations: {avg_iters:.2f}\")\n",
        "        return avg_iters\n",
        "    else:\n",
        "        avg_loss = acc_loss / num_loss\n",
        "        print(f\"Validation loss: {avg_loss:.4f}\")\n",
        "        return avg_loss"
      ],
      "metadata": {
        "id": "bRETenOFREJj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NeuralIF model"
      ],
      "metadata": {
        "id": "6pz6E3na4ruX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralIF(nn.Module):\n",
        "    # Neural Incomplete factorization\n",
        "    def __init__(self, drop_tol=0, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.global_features = kwargs[\"global_features\"]\n",
        "        self.latent_size = kwargs[\"latent_size\"]\n",
        "        # node features are augmented with local degree profile\n",
        "        self.augment_node_features = kwargs[\"augment_nodes\"]\n",
        "\n",
        "        num_node_features = 8 if self.augment_node_features else 1\n",
        "        message_passing_steps = kwargs[\"message_passing_steps\"]\n",
        "\n",
        "        # edge feature representation in the latent layers\n",
        "        edge_features = kwargs.get(\"edge_features\", 1)\n",
        "\n",
        "        self.skip_connections = kwargs[\"skip_connections\"]\n",
        "\n",
        "        self.mps = torch.nn.ModuleList()\n",
        "        for l in range(message_passing_steps):\n",
        "            # skip connections are added to all layers except the first one\n",
        "            self.mps.append(MP_Block(skip_connections=self.skip_connections,\n",
        "                                     first=l==0,\n",
        "                                     last=l==(message_passing_steps-1),\n",
        "                                     edge_features=edge_features,\n",
        "                                     node_features=num_node_features,\n",
        "                                     global_features=self.global_features,\n",
        "                                     hidden_size=self.latent_size,\n",
        "                                     activation=kwargs[\"activation\"],\n",
        "                                     aggregate=kwargs[\"aggregate\"]))\n",
        "\n",
        "        # node decodings\n",
        "        self.node_decoder = MLP([num_node_features, self.latent_size, 1]) if kwargs[\"decode_nodes\"] else None\n",
        "\n",
        "        # diag-aggregation for normalization of rows\n",
        "        self.normalize_diag = kwargs[\"normalize_diag\"] if \"normalize_diag\" in kwargs else False\n",
        "        self.diag_aggregate = aggr.SumAggregation()\n",
        "\n",
        "        # normalization\n",
        "        self.graph_norm = pyg.norm.GraphNorm(num_node_features) if (\"graph_norm\" in kwargs and kwargs[\"graph_norm\"]) else None\n",
        "\n",
        "        # drop tolerance and additional fill-ins and more sparsity\n",
        "        self.tau = drop_tol\n",
        "        self.two = kwargs.get(\"two_hop\", False)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # ! data could be batched here...(not implemented)\n",
        "\n",
        "        if self.augment_node_features:\n",
        "            data = augment_features(data, skip_rhs=True)\n",
        "\n",
        "        # add additional edges to the data\n",
        "        if self.two:\n",
        "            data = TwoHop()(data)\n",
        "\n",
        "        # * in principle it is possible to integrate reordering here.\n",
        "\n",
        "        data = ToLowerTriangular()(data)\n",
        "\n",
        "        # get the input data\n",
        "        edge_embedding = data.edge_attr\n",
        "        l_index = data.edge_index\n",
        "\n",
        "        if self.graph_norm is not None:\n",
        "            node_embedding = self.graph_norm(data.x, batch=data.batch)\n",
        "        else:\n",
        "            node_embedding = data.x\n",
        "\n",
        "        # copy the input data (only edges of original matrix A)\n",
        "        a_edges = edge_embedding.clone()\n",
        "\n",
        "        if self.global_features > 0:\n",
        "            global_features = torch.zeros((1, self.global_features), device=data.x.device, requires_grad=False)\n",
        "            # feature ideas: nnz, 1-norm, inf-norm col/row var, min/max variability, avg distances to nnz\n",
        "        else:\n",
        "            global_features = None\n",
        "\n",
        "        # compute the output of the network\n",
        "        for i, layer in enumerate(self.mps):\n",
        "            if i != 0 and self.skip_connections:\n",
        "                edge_embedding = torch.cat([edge_embedding, a_edges], dim=1)\n",
        "\n",
        "            edge_embedding, node_embedding, global_features = layer(node_embedding, l_index, edge_embedding, global_features)\n",
        "\n",
        "        # transform the output into a matrix\n",
        "        return self.transform_output_matrix(node_embedding, l_index, edge_embedding, a_edges)\n",
        "\n",
        "    def transform_output_matrix(self, node_x, edge_index, edge_values, a_edges):\n",
        "        # force diagonal to be positive\n",
        "        diag = edge_index[0] == edge_index[1]\n",
        "\n",
        "        # normalize diag such that it has zero residual\n",
        "        if self.normalize_diag:\n",
        "            # copy the diag of matrix A\n",
        "            a_diag = a_edges[diag]\n",
        "\n",
        "            # compute the row norm\n",
        "            square_values = torch.pow(edge_values, 2)\n",
        "            aggregated = self.diag_aggregate(square_values, edge_index[0])\n",
        "\n",
        "            # now, we renormalize the edge values such that they are the square root of the original value...\n",
        "            edge_values = torch.sqrt(a_diag[edge_index[0]]) * edge_values / torch.sqrt(aggregated[edge_index[0]])\n",
        "\n",
        "        else:\n",
        "            # otherwise, just take the edge values as they are...\n",
        "            # but take the square root as it is numerically better\n",
        "            # edge_values[diag] = torch.exp(edge_values[diag])\n",
        "            edge_values[diag] = torch.sqrt(torch.exp(edge_values[diag]))\n",
        "\n",
        "        # node decoder\n",
        "        node_output = self.node_decoder(node_x).squeeze() if self.node_decoder is not None else None\n",
        "\n",
        "        # ! this if should only be activated when the model is in production!!\n",
        "        if torch.is_inference_mode_enabled():\n",
        "\n",
        "            # we can decide to remove small elements during inference from the preconditioner matrix\n",
        "            if self.tau != 0:\n",
        "                small_value = (torch.abs(edge_values) <= self.tau).squeeze()\n",
        "\n",
        "                # small value and not diagonal\n",
        "                elems = torch.logical_and(small_value, torch.logical_not(diag))\n",
        "\n",
        "                # might be able to do this easily!\n",
        "                edge_values[elems] = 0\n",
        "\n",
        "                # remove zeros from the sparse representation\n",
        "                filt = (edge_values != 0).squeeze()\n",
        "                edge_values = edge_values[filt]\n",
        "                edge_index = edge_index[:, filt]\n",
        "\n",
        "            # ! this is the way to go!!\n",
        "            # Doing pytorch -> scipy -> numml is a lot faster than pytorch -> numml on CPU\n",
        "            # On GPU it is faster to go to pytorch -> numml -> CPU\n",
        "\n",
        "            # convert to scipy sparse matrix\n",
        "            # m = to_scipy_sparse_matrix(edge_index, matrix_values)\n",
        "            m = torch.sparse_coo_tensor(edge_index, edge_values.squeeze(),\n",
        "                                        size=(node_x.size()[0], node_x.size()[0]))\n",
        "                                        # type=torch.double)\n",
        "\n",
        "            # produce L and U seperatly\n",
        "            l = SparseCSRTensor(m)\n",
        "            u = SparseCSRTensor(m.T)\n",
        "\n",
        "            return l, u, node_output\n",
        "\n",
        "        else:\n",
        "            # For training and testing (computing regular losses for examples.)\n",
        "            # does not need to be performance optimized!\n",
        "            # use torch sparse directly\n",
        "            t = torch.sparse_coo_tensor(edge_index, edge_values.squeeze(),\n",
        "                                        size=(node_x.size()[0], node_x.size()[0]))\n",
        "\n",
        "            # normalized l1 norm is best computed here!\n",
        "            # l2_nn = torch.linalg.norm(edge_values, ord=2)\n",
        "            l1_penalty = torch.sum(torch.abs(edge_values)) / len(edge_values)\n",
        "\n",
        "            return t, l1_penalty, node_output\n"
      ],
      "metadata": {
        "id": "fo19YfVkW3cT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training"
      ],
      "metadata": {
        "id": "C_ySuevTbPWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Training Configuration"
      ],
      "metadata": {
        "id": "p9Rge5QlbVmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"name\": \"experiment_1\",\n",
        "    \"save\": True,\n",
        "    \"seed\": 42,\n",
        "    \"n\": 0,\n",
        "    \"batch_size\": 1,\n",
        "    \"num_epochs\": 100,\n",
        "    \"dataset\": \"random\",\n",
        "    \"loss\": \"frobenius\",\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"regularizer\": 0.0,\n",
        "    \"scheduler\": False,\n",
        "    \"model\": \"neuralif\",\n",
        "    \"normalize\": False,\n",
        "    \"latent_size\": 8,\n",
        "    \"message_passing_steps\": 3,\n",
        "    \"decode_nodes\": False,\n",
        "    \"normalize_diag\": False,\n",
        "    \"aggregate\": [\"mean\", \"sum\"],\n",
        "    \"activation\": \"relu\",\n",
        "    \"skip_connections\": True,\n",
        "    \"augment_nodes\": False,\n",
        "    \"global_features\": 0,\n",
        "    \"edge_features\": 1,\n",
        "    \"graph_norm\": False,\n",
        "    \"two_hop\": False,\n",
        "}\n",
        "\n",
        "# Prepare output folder\n",
        "if config[\"name\"]:\n",
        "    folder = f\"results/{config['name']}\"\n",
        "else:\n",
        "    folder = datetime.datetime.now().strftime(\"results/%Y-%m-%d_%H-%M-%S\")\n",
        "if config[\"save\"]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    save_dict_to_file(config, os.path.join(folder, \"config.json\"))\n"
      ],
      "metadata": {
        "id": "Og3JzHyyQ5-x"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed for reproducibility\n",
        "torch_geometric.seed_everything(config[\"seed\"])\n",
        "\n",
        "# Select model\n",
        "model_args = {k: config[k] for k in [\n",
        "    \"latent_size\", \"message_passing_steps\", \"skip_connections\",\n",
        "    \"augment_nodes\", \"global_features\", \"decode_nodes\",\n",
        "    \"normalize_diag\", \"activation\", \"aggregate\", \"graph_norm\",\n",
        "    \"two_hop\", \"edge_features\", \"normalize\"\n",
        "] if k in config}\n",
        "\n",
        "use_gmres = False\n",
        "if config[\"model\"] == \"__\":\n",
        "    model = NeuralPCG(**model_args)\n",
        "elif config[\"model\"] in (\"nif\", \"neuralif\", \"inf\"):\n",
        "    model = NeuralIF(**model_args)\n",
        "else:\n",
        "    raise ValueError(\"Unknown model type\")\n",
        "\n",
        "model.to(device)\n",
        "print(\"Number of parameters:\", count_parameters(model))\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.5, patience=20\n",
        ")"
      ],
      "metadata": {
        "id": "tJnpsDJBRzJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64dfe46a-40a5-4990-8344-ffeb397dc055"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = get_dataloader(config[\"dataset\"], config[\"n\"], config[\"batch_size\"],\n",
        "                                  spd=not gmres, mode=\"train\")\n",
        "\n",
        "validation_loader = get_dataloader(config[\"dataset\"], config[\"n\"], 1, spd=(not gmres), mode=\"val\")"
      ],
      "metadata": {
        "id": "vknOPTMW-9MU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "best_val = float(\"inf\")\n",
        "logger = TrainResults(folder)\n",
        "total_it = 0\n",
        "\n",
        "for epoch in range(config[\"num_epochs\"]):\n",
        "    running_loss = 0.0\n",
        "    start_epoch = time.perf_counter()\n",
        "\n",
        "    for data in train_loader:\n",
        "        total_it += 1\n",
        "        model.train()\n",
        "\n",
        "        start = time.perf_counter()\n",
        "        data = data.to(device)\n",
        "\n",
        "        output, reg, _ = model(data)\n",
        "        l = loss(output, data, c=reg, config=config[\"loss\"])\n",
        "        l.backward()\n",
        "\n",
        "        # gradient clipping or manual norm\n",
        "        if config[\"gradient_clipping\"]:\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                model.parameters(), config[\"gradient_clipping\"]\n",
        "            )\n",
        "        else:\n",
        "            total_norm = sum(\n",
        "                p.grad.detach().data.norm(2).item() ** 2\n",
        "                for p in model.parameters() if p.grad is not None\n",
        "            )\n",
        "            grad_norm = (total_norm ** 0.5) / config[\"batch_size\"]\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += l.item()\n",
        "        logger.log(l.item(), grad_norm, time.perf_counter() - start)\n",
        "\n",
        "        # periodic validation\n",
        "        if total_it % 1000 == 0:\n",
        "            val_metric = validate(\n",
        "                model, validation_loader, solve=True,\n",
        "                solver=\"gmres\" if use_gmres else \"cg\"\n",
        "            )\n",
        "            logger.log_val(None, val_metric)\n",
        "            if val_metric < best_val:\n",
        "                best_val = val_metric\n",
        "                if config[\"save\"]:\n",
        "                    torch.save(model.state_dict(), f\"{folder}/best_model.pt\")\n",
        "\n",
        "    epoch_time = time.perf_counter() - start_epoch\n",
        "    print(f\"Epoch {epoch+1} — loss: {running_loss/len(train_loader):.4f}, time: {epoch_time:.1f}s\")\n",
        "    if config[\"save\"]:\n",
        "        torch.save(model.state_dict(), f\"{folder}/model_epoch{epoch+1}.pt\")\n"
      ],
      "metadata": {
        "id": "sMSaRR7cSMFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "11b62d6e-ad7f-404f-d964-0ddc84ddb18a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 — loss: 377.9307, time: 43.9s\n",
            "Epoch 2 — loss: 542.5479, time: 47.3s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-9871e1e4dca1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# gradient clipping or manual norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save results\n",
        "if config[\"save\"]:\n",
        "    logger.save_results()\n",
        "    torch.save(model.to(torch.float).state_dict(), f\"{folder}/final_model.pt\")\n"
      ],
      "metadata": {
        "id": "vom7sud2SSpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test printout\n",
        "print(\"Best validation performance:\", best_val)"
      ],
      "metadata": {
        "id": "5JqtkgTZSaSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}