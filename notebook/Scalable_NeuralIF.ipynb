{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "zmYSP8cAZFaG",
        "4Jmnl78bbJzG"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scalable GNN–Based Preconditioners for Conjugate Gradient Methods\n",
        "**Authors: Nicholas Tan Yun Yu, Low Jun Yu, Yuhan Wu**\n",
        "\n",
        "This project was inspired by [NeuralIF](https://arxiv.org/abs/2305.16368).\n",
        "\n",
        "**Summary**: The authors come up with a novel message-passing GNN block that is used by the network to predict efficient preconditioners to solve sparse linear systems. These preconditioners are tested using the preconditioned conjugate gradient (CG) method, which make the algorithm converge faster than other state-of-the-art preconditioners.\n",
        "\n",
        "**Motivation**: Modern data-driven and physics-based applications frequently force us to deal with dense matrices. Therefore, we hope to show that the message-passing GNN block can learn effective preconditioners for these scaled up fields. An example of a machine learning problem that could benefit from this is Gaussian Processes, which makes use of a dense kernel function as such: (some image)\n",
        "\n",
        "**The problem**: Scaling the problem to dense matrices is nontrivial. The Coates graph representation has 1 node per row/column, and one edge only for each nonzero entry in A. For a dense n*n matrix, that graph becomes complete – with n^2 edges – so both memory and compute blow up to O(n^2).\n",
        "\n",
        "**Research direction**: Implement an edge-regression GNN that can work on dense matrices. We can achieve this using sampling techniques such as GraphSAGE and Cluster-GCN."
      ],
      "metadata": {
        "id": "J_CMa5FedgDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installation & Setup"
      ],
      "metadata": {
        "id": "XrqVh2BF7LhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load files from google drive"
      ],
      "metadata": {
        "id": "-4MVBD1eXd8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSuii7-phJYZ",
        "outputId": "3256fd1d-591a-4022-e489-30ef882129ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add directory to python's path\n",
        "# This directory path should lead straight to the root of the project\n",
        "# Ensure that the project's root directory has the folders \"krylov\", \"apps\" and \"neuralif\"\n",
        "#   that has the files contained in https://github.com/paulhausner/neural-incomplete-factorization/tree/main\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CS4350/project/')"
      ],
      "metadata": {
        "id": "tbuq9axkgIj_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package installation"
      ],
      "metadata": {
        "id": "ehpIKqQaX36-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aT_oBJ5bbQu",
        "outputId": "730d3617-1d5d-4f68-eeff-c7665f0d99de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q pyg-lib -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "%pip install -q torch torchvision torchaudio\n",
        "%pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.6.0+cu124.html  # prevents the wheel from taking forever to build\n",
        "%pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.6.0+cu124.html   # prevents the wheel from taking forever to build\n",
        "%pip install -q torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu124.html  # prevents the wheel from taking forever to build\n",
        "%pip install -q torch_geometric"
      ],
      "metadata": {
        "id": "WuLYpuGUDMoA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run this only if you don't already have a copy of the built numml wheel on google drive (~7 mins)\n",
        "# build the wheel just once and then store in google drive /content/drive/MyDrive/CS4350/project/wheels\n",
        "!git clone https://github.com/nicknytko/numml.git\n",
        "%cd numml\n",
        "!pip install --upgrade build\n",
        "!python -m build --wheel\n",
        "!mkdir -p /content/drive/MyDrive/CS4350/project/wheels\n",
        "!mv dist/*.whl /content/drive/MyDrive/CS4350/project/wheels\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkqxiHg9d_JM",
        "outputId": "de35cc17-9f77-4894-df21-3d05ce17f722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'numml' already exists and is not an empty directory.\n",
            "/content/numml\n",
            "/content/numml\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.11/dist-packages (1.2.2.post1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build) (1.2.0)\n",
            "\u001b[1m* Creating isolated environment: venv+pip...\u001b[0m\n",
            "\u001b[1m* Installing packages in isolated environment:\u001b[0m\n",
            "  - setuptools>=42\n",
            "  - torch\n",
            "\u001b[1m* Getting build dependencies for wheel...\u001b[0m\n",
            "/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
            "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
            "Detected CUDA install of Torch, compiling with CUDA acceleration...\n",
            "running egg_info\n",
            "writing numml.egg-info/PKG-INFO\n",
            "writing dependency_links to numml.egg-info/dependency_links.txt\n",
            "writing requirements to numml.egg-info/requires.txt\n",
            "writing top-level names to numml.egg-info/top_level.txt\n",
            "/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/utils/cpp_extension.py:576: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'numml.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE.md'\n",
            "writing manifest file 'numml.egg-info/SOURCES.txt'\n",
            "\u001b[1m* Building wheel...\u001b[0m\n",
            "/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
            "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
            "Detected CUDA install of Torch, compiling with CUDA acceleration...\n",
            "running bdist_wheel\n",
            "/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/utils/cpp_extension.py:576: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "running build\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-cpython-311/numml\n",
            "copying numml/profiler.py -> build/lib.linux-x86_64-cpython-311/numml\n",
            "copying numml/autograd.py -> build/lib.linux-x86_64-cpython-311/numml\n",
            "copying numml/krylov.py -> build/lib.linux-x86_64-cpython-311/numml\n",
            "copying numml/iterative.py -> build/lib.linux-x86_64-cpython-311/numml\n",
            "copying numml/utils.py -> build/lib.linux-x86_64-cpython-311/numml\n",
            "copying numml/__init__.py -> build/lib.linux-x86_64-cpython-311/numml\n",
            "copying numml/nn.py -> build/lib.linux-x86_64-cpython-311/numml\n",
            "copying numml/version.py -> build/lib.linux-x86_64-cpython-311/numml\n",
            "creating build/lib.linux-x86_64-cpython-311/numml/sparse\n",
            "copying numml/sparse/_linear_operator.py -> build/lib.linux-x86_64-cpython-311/numml/sparse\n",
            "copying numml/sparse/linalg.py -> build/lib.linux-x86_64-cpython-311/numml/sparse\n",
            "copying numml/sparse/_csr.py -> build/lib.linux-x86_64-cpython-311/numml/sparse\n",
            "copying numml/sparse/__init__.py -> build/lib.linux-x86_64-cpython-311/numml/sparse\n",
            "running egg_info\n",
            "writing numml.egg-info/PKG-INFO\n",
            "writing dependency_links to numml.egg-info/dependency_links.txt\n",
            "writing requirements to numml.egg-info/requires.txt\n",
            "writing top-level names to numml.egg-info/top_level.txt\n",
            "reading manifest file 'numml.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE.md'\n",
            "writing manifest file 'numml.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/utils/cpp_extension.py:480: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.6). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/utils/cpp_extension.py:490: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'numml_torch_cpp' extension\n",
            "creating build/temp.linux-x86_64-cpython-311/cpp\n",
            "/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "/usr/local/cuda/bin/nvcc -I/content/numml/ext/cuCollections/include -I/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/include -I/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/tmp/build-env-g4iatkxy/include -I/usr/include/python3.11 -c cpp/cuda_common.cu -o build/temp.linux-x86_64-cpython-311/cpp/cuda_common.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -DTORCH_EXTENSION_NAME=numml_torch_cpp -D_GLIBCXX_USE_CXX11_ABI=1 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/numml/ext/cuCollections/include -I/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/include -I/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/tmp/build-env-g4iatkxy/include -I/usr/include/python3.11 -c cpp/sparse_csr.cpp -o build/temp.linux-x86_64-cpython-311/cpp/sparse_csr.o -DCUDA_ENABLED=1 -O2 -std=c++17 -w -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -DTORCH_EXTENSION_NAME=numml_torch_cpp -D_GLIBCXX_USE_CXX11_ABI=1\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/numml/ext/cuCollections/include -I/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/include -I/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/tmp/build-env-g4iatkxy/include -I/usr/include/python3.11 -c cpp/sparse_csr_cpu.cpp -o build/temp.linux-x86_64-cpython-311/cpp/sparse_csr_cpu.o -DCUDA_ENABLED=1 -O2 -std=c++17 -w -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -DTORCH_EXTENSION_NAME=numml_torch_cpp -D_GLIBCXX_USE_CXX11_ABI=1\n",
            "/usr/local/cuda/bin/nvcc -I/content/numml/ext/cuCollections/include -I/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/include -I/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/tmp/build-env-g4iatkxy/include -I/usr/include/python3.11 -c cpp/sparse_csr_cuda.cu -o build/temp.linux-x86_64-cpython-311/cpp/sparse_csr_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -DTORCH_EXTENSION_NAME=numml_torch_cpp -D_GLIBCXX_USE_CXX11_ABI=1 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "/usr/local/cuda/bin/nvcc -I/content/numml/ext/cuCollections/include -I/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/include -I/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/usr/local/cuda/include -I/tmp/build-env-g4iatkxy/include -I/usr/include/python3.11 -c cpp/sparse_csr_gemm_cuda.cu -o build/temp.linux-x86_64-cpython-311/cpp/sparse_csr_gemm_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -DTORCH_EXTENSION_NAME=numml_torch_cpp -D_GLIBCXX_USE_CXX11_ABI=1 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75\n",
            "\u001b[01m\u001b[0m\u001b[01mcpp/sparse_csr_gemm_cuda.cu(228)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"C_cols\"\u001b[0m was declared but never referenced\n",
            "      const int C_cols = B_cols;\n",
            "                ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mcpp/sparse_csr_gemm_cuda.cu(392)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"j_i\"\u001b[0m was declared but never referenced\n",
            "      int64_t k_i, j_i;\n",
            "                   ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mcpp/sparse_csr_gemm_cuda.cu(666)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"C_rows\"\u001b[0m was declared but never referenced\n",
            "      const int C_rows = A_rows;\n",
            "                ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mcpp/sparse_csr_gemm_cuda.cu(667)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"C_cols\"\u001b[0m was declared but never referenced\n",
            "      const int C_cols = B_cols;\n",
            "                ^\n",
            "\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions build/temp.linux-x86_64-cpython-311/cpp/cuda_common.o build/temp.linux-x86_64-cpython-311/cpp/sparse_csr.o build/temp.linux-x86_64-cpython-311/cpp/sparse_csr_cpu.o build/temp.linux-x86_64-cpython-311/cpp/sparse_csr_cuda.o build/temp.linux-x86_64-cpython-311/cpp/sparse_csr_gemm_cuda.o -L/tmp/build-env-g4iatkxy/lib/python3.11/site-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/numml_torch_cpp.cpython-311-x86_64-linux-gnu.so\n",
            "installing to build/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64/wheel\n",
            "creating build/bdist.linux-x86_64/wheel/numml\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/profiler.py -> build/bdist.linux-x86_64/wheel/./numml\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/autograd.py -> build/bdist.linux-x86_64/wheel/./numml\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/krylov.py -> build/bdist.linux-x86_64/wheel/./numml\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/iterative.py -> build/bdist.linux-x86_64/wheel/./numml\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/utils.py -> build/bdist.linux-x86_64/wheel/./numml\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/__init__.py -> build/bdist.linux-x86_64/wheel/./numml\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/nn.py -> build/bdist.linux-x86_64/wheel/./numml\n",
            "creating build/bdist.linux-x86_64/wheel/numml/sparse\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/sparse/_linear_operator.py -> build/bdist.linux-x86_64/wheel/./numml/sparse\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/sparse/linalg.py -> build/bdist.linux-x86_64/wheel/./numml/sparse\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/sparse/_csr.py -> build/bdist.linux-x86_64/wheel/./numml/sparse\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/sparse/__init__.py -> build/bdist.linux-x86_64/wheel/./numml/sparse\n",
            "copying build/lib.linux-x86_64-cpython-311/numml/version.py -> build/bdist.linux-x86_64/wheel/./numml\n",
            "copying build/lib.linux-x86_64-cpython-311/numml_torch_cpp.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
            "running install_egg_info\n",
            "Copying numml.egg-info to build/bdist.linux-x86_64/wheel/./numml-0.1.0-py3.11.egg-info\n",
            "running install_scripts\n",
            "creating build/bdist.linux-x86_64/wheel/numml-0.1.0.dist-info/WHEEL\n",
            "creating '/content/numml/dist/.tmp-sw3z3ijn/numml-0.1.0-cp311-cp311-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "adding 'numml_torch_cpp.cpython-311-x86_64-linux-gnu.so'\n",
            "adding 'numml/__init__.py'\n",
            "adding 'numml/autograd.py'\n",
            "adding 'numml/iterative.py'\n",
            "adding 'numml/krylov.py'\n",
            "adding 'numml/nn.py'\n",
            "adding 'numml/profiler.py'\n",
            "adding 'numml/utils.py'\n",
            "adding 'numml/version.py'\n",
            "adding 'numml/sparse/__init__.py'\n",
            "adding 'numml/sparse/_csr.py'\n",
            "adding 'numml/sparse/_linear_operator.py'\n",
            "adding 'numml/sparse/linalg.py'\n",
            "adding 'numml-0.1.0.dist-info/licenses/LICENSE.md'\n",
            "adding 'numml-0.1.0.dist-info/METADATA'\n",
            "adding 'numml-0.1.0.dist-info/WHEEL'\n",
            "adding 'numml-0.1.0.dist-info/top_level.txt'\n",
            "adding 'numml-0.1.0.dist-info/RECORD'\n",
            "removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[1m\u001b[92mSuccessfully built \u001b[4mnumml-0.1.0-cp311-cp311-linux_x86_64.whl\u001b[0m\u001b[1m\u001b[92m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# once the .whl file is in the drive, just run this cell to install numml within seconds\n",
        "!pip install \\\n",
        "  /content/drive/MyDrive/CS4350/project/wheels/numml-0.1.0-cp311-cp311-linux_x86_64.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDq3-HeZezaN",
        "outputId": "c6dcce55-c63b-4837-9c06-d87978160666"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./drive/MyDrive/CS4350/project/wheels/numml-0.1.0-cp311-cp311-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from numml==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from numml==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->numml==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->numml==0.1.0) (3.0.2)\n",
            "numml is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # full rebuilduing of the wheel for numml package each time ~7 mins\n",
        "# !git clone https://github.com/nicknytko/numml.git\n",
        "# !pip3 install -e numml/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KGYzsShHXY_",
        "outputId": "f0968c43-5c3e-4498-de79-5f80f99570c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'numml' already exists and is not an empty directory.\n",
            "Obtaining file:///content/numml\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from numml==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from numml==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->numml==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->numml==0.1.0) (3.0.2)\n",
            "Building wheels for collected packages: numml\n",
            "  Building editable for numml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numml: filename=numml-0.1.0-0.editable-cp311-cp311-linux_x86_64.whl size=4243 sha256=0f220ae7a8c761eaea47fd3377a22b4c27724d5d3a9483452abdfa12bdc05fc7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-av6sa9yo/wheels/e4/c7/60/5c5dbff4a2bca3147d0cd3159ffd391d2cc28ebe1c9555eb4c\n",
            "Successfully built numml\n",
            "Installing collected packages: numml\n",
            "Successfully installed numml-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "HgiuVFCFX9Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "import pprint\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg\n",
        "from torch_geometric.nn import aggr\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.data import Batch\n",
        "from scipy.sparse import tril, coo_matrix\n",
        "\n",
        "from apps.data import get_dataloader, graph_to_matrix, matrix_to_graph, FolderDataset\n",
        "from neuralif.utils import (\n",
        "    count_parameters, save_dict_to_file,\n",
        "    condition_number, eigenval_distribution, gershgorin_norm,\n",
        "    TwoHop\n",
        ")\n",
        "from neuralif.logger import TrainResults, TestResults\n",
        "from neuralif.loss import loss\n",
        "\n",
        "from krylov.cg import preconditioned_conjugate_gradient\n",
        "from krylov.gmres import gmres\n",
        "\n",
        "# import from self-curated numml file\n",
        "# from numml import SparseCSRTensor"
      ],
      "metadata": {
        "id": "c3uK7LjaQoMt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set GPU"
      ],
      "metadata": {
        "id": "1BzKAAbyYE59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDfXtM3xQzwJ",
        "outputId": "2a75bc7e-173f-4894-a065-4b54d592b9e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset generation"
      ],
      "metadata": {
        "id": "zmYSP8cAZFaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "cA9OMUsXaQKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sparse_random(n, alpha=1e-4, random_state=0, sol=False, ood=False):\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    if alpha is None:\n",
        "        alpha = rng.uniform(1e-4, 1e-2)\n",
        "    sparsity = 10e-4  # this is 1% sparsity for n = 10 000\n",
        "\n",
        "    if ood:\n",
        "        factor = rng.uniform(0.22, 2.2)\n",
        "        sparsity *= factor\n",
        "\n",
        "    nnz = int(sparsity * n ** 2)\n",
        "    rows = [rng.randint(0, n) for _ in range(nnz)]\n",
        "    cols = [rng.randint(0, n) for _ in range(nnz)]\n",
        "    uniques = set(zip(rows, cols))\n",
        "    rows, cols = zip(*uniques)\n",
        "    vals = rng.normal(0, 1, size=len(cols))\n",
        "\n",
        "    M = coo_matrix((vals, (rows, cols)), shape=(n, n))\n",
        "    I = scipy.sparse.identity(n)\n",
        "    A = (M @ M.T) + alpha * I # create spd matrix\n",
        "    print(f\"Generated matrix with {100 * (A.nnz / n**2):.2f}% non-zeros ({A.nnz} entries)\")\n",
        "\n",
        "    b = rng.uniform(0, 1, size=n)\n",
        "    x = None\n",
        "    if sol:\n",
        "        x, _ = scipy.sparse.linalg.cg(A, b)\n",
        "    return A, x, b\n",
        "\n",
        "def create_dataset(n, samples, alpha=1e-2, graph=True, rs=0, mode='train', solution=False):\n",
        "    if mode != 'train' and rs == 0:\n",
        "        raise ValueError('`rs` must be non-zero for val/test to avoid overlap')\n",
        "\n",
        "    print(f\"Creating {samples} samples for '{mode}' set (n={n})\")\n",
        "    for sam in range(samples):\n",
        "        A, x, b = generate_sparse_random(\n",
        "            n, alpha=alpha, random_state=rs + sam,\n",
        "            sol=solution, ood=(mode == \"test_ood\")\n",
        "        )\n",
        "        if graph:\n",
        "            g = matrix_to_graph(A, b)\n",
        "            if x is not None:\n",
        "                g.s = torch.tensor(x, dtype=torch.float)\n",
        "            g.n = n\n",
        "            torch.save(g, f'./data/Random/{mode}/{n}_{sam}.pt')\n",
        "        else:\n",
        "            scipy.sparse.save_npz(f'./data/Random/{mode}/{n}_{sam}.npz', A)\n",
        "            np.savez(f'./data/Random/{mode}/{n}_{sam}.npz', A=A, b=b, x=x)\n"
      ],
      "metadata": {
        "id": "JKMq525PZEId"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Train, Validation and Test datasets"
      ],
      "metadata": {
        "id": "2Coq9OGHdUm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure target folders exist\n",
        "for split in ['train', 'val', 'test']:\n",
        "    os.makedirs(f'./data/Random/{split}', exist_ok=True)\n",
        "\n",
        "# parameters\n",
        "n = 10_00\n",
        "alpha = 1e-4\n",
        "\n",
        "# generate\n",
        "create_dataset(n, samples=100, alpha=alpha, mode='train', rs=0, graph=True, solution=True)\n",
        "create_dataset(n, samples=5, alpha=alpha, mode='val', rs=10000, graph=True, solution=False)\n",
        "create_dataset(n, samples=20, alpha=alpha, mode='test', rs=103600, graph=True, solution=False)\n"
      ],
      "metadata": {
        "id": "lWJ7E9ZEaCQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29fa61ee-cee7-4ca6-9037-b7ed896dfbbb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating 100 samples for 'train' set (n=1000)\n",
            "Generated matrix with 0.21% non-zeros (2078 entries)\n",
            "Generated matrix with 0.21% non-zeros (2072 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1978 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (1962 entries)\n",
            "Generated matrix with 0.20% non-zeros (2032 entries)\n",
            "Generated matrix with 0.21% non-zeros (2066 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (2008 entries)\n",
            "Generated matrix with 0.20% non-zeros (2018 entries)\n",
            "Generated matrix with 0.20% non-zeros (2040 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (2010 entries)\n",
            "Generated matrix with 0.20% non-zeros (2006 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.19% non-zeros (1918 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1964 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1962 entries)\n",
            "Generated matrix with 0.20% non-zeros (2042 entries)\n",
            "Generated matrix with 0.20% non-zeros (2010 entries)\n",
            "Generated matrix with 0.20% non-zeros (1982 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n",
            "Generated matrix with 0.20% non-zeros (1988 entries)\n",
            "Generated matrix with 0.21% non-zeros (2072 entries)\n",
            "Generated matrix with 0.19% non-zeros (1950 entries)\n",
            "Generated matrix with 0.20% non-zeros (1960 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1974 entries)\n",
            "Generated matrix with 0.20% non-zeros (1984 entries)\n",
            "Generated matrix with 0.19% non-zeros (1904 entries)\n",
            "Generated matrix with 0.20% non-zeros (2044 entries)\n",
            "Generated matrix with 0.20% non-zeros (2044 entries)\n",
            "Generated matrix with 0.20% non-zeros (1976 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (2008 entries)\n",
            "Generated matrix with 0.21% non-zeros (2108 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (1974 entries)\n",
            "Generated matrix with 0.19% non-zeros (1944 entries)\n",
            "Generated matrix with 0.20% non-zeros (2006 entries)\n",
            "Generated matrix with 0.20% non-zeros (1982 entries)\n",
            "Generated matrix with 0.21% non-zeros (2086 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (1988 entries)\n",
            "Generated matrix with 0.21% non-zeros (2054 entries)\n",
            "Generated matrix with 0.20% non-zeros (2018 entries)\n",
            "Generated matrix with 0.20% non-zeros (2000 entries)\n",
            "Generated matrix with 0.20% non-zeros (2018 entries)\n",
            "Generated matrix with 0.20% non-zeros (2026 entries)\n",
            "Generated matrix with 0.20% non-zeros (1974 entries)\n",
            "Generated matrix with 0.19% non-zeros (1938 entries)\n",
            "Generated matrix with 0.21% non-zeros (2062 entries)\n",
            "Generated matrix with 0.19% non-zeros (1948 entries)\n",
            "Generated matrix with 0.20% non-zeros (2008 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (2000 entries)\n",
            "Generated matrix with 0.20% non-zeros (1964 entries)\n",
            "Generated matrix with 0.20% non-zeros (1972 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (2002 entries)\n",
            "Generated matrix with 0.20% non-zeros (1984 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n",
            "Generated matrix with 0.21% non-zeros (2050 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2012 entries)\n",
            "Generated matrix with 0.19% non-zeros (1936 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (2026 entries)\n",
            "Generated matrix with 0.20% non-zeros (1958 entries)\n",
            "Generated matrix with 0.21% non-zeros (2070 entries)\n",
            "Generated matrix with 0.20% non-zeros (2012 entries)\n",
            "Generated matrix with 0.20% non-zeros (1976 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2012 entries)\n",
            "Generated matrix with 0.20% non-zeros (2022 entries)\n",
            "Generated matrix with 0.20% non-zeros (2004 entries)\n",
            "Generated matrix with 0.20% non-zeros (2028 entries)\n",
            "Generated matrix with 0.20% non-zeros (1958 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2034 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.19% non-zeros (1932 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2010 entries)\n",
            "Generated matrix with 0.20% non-zeros (1956 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (2030 entries)\n",
            "Generated matrix with 0.20% non-zeros (1964 entries)\n",
            "Generated matrix with 0.20% non-zeros (2032 entries)\n",
            "Generated matrix with 0.20% non-zeros (1960 entries)\n",
            "Creating 5 samples for 'val' set (n=1000)\n",
            "Generated matrix with 0.19% non-zeros (1936 entries)\n",
            "Generated matrix with 0.20% non-zeros (2042 entries)\n",
            "Generated matrix with 0.21% non-zeros (2090 entries)\n",
            "Generated matrix with 0.19% non-zeros (1936 entries)\n",
            "Generated matrix with 0.21% non-zeros (2074 entries)\n",
            "Creating 20 samples for 'test' set (n=1000)\n",
            "Generated matrix with 0.20% non-zeros (2026 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.21% non-zeros (2114 entries)\n",
            "Generated matrix with 0.20% non-zeros (2044 entries)\n",
            "Generated matrix with 0.20% non-zeros (2020 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (1978 entries)\n",
            "Generated matrix with 0.19% non-zeros (1900 entries)\n",
            "Generated matrix with 0.20% non-zeros (2020 entries)\n",
            "Generated matrix with 0.20% non-zeros (2004 entries)\n",
            "Generated matrix with 0.20% non-zeros (1952 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n",
            "Generated matrix with 0.19% non-zeros (1926 entries)\n",
            "Generated matrix with 0.20% non-zeros (2000 entries)\n",
            "Generated matrix with 0.19% non-zeros (1924 entries)\n",
            "Generated matrix with 0.20% non-zeros (1988 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1982 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model"
      ],
      "metadata": {
        "id": "4Jmnl78bbJzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper classes and functions"
      ],
      "metadata": {
        "id": "uVkV8IKb4uV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "#          Layers          #\n",
        "############################\n",
        "class GraphNet(nn.Module):\n",
        "    # Follows roughly the outline of torch_geometric.nn.MessagePassing()\n",
        "    # As shown in https://github.com/deepmind/graph_nets\n",
        "    # Here is a helpful python implementation:\n",
        "    # https://github.com/NVIDIA/GraphQSat/blob/main/gqsat/models.py\n",
        "    # Also allows multirgaph GNN via edge_2_features\n",
        "    def __init__(self, node_features, edge_features, global_features=0, hidden_size=0,\n",
        "                 aggregate=\"mean\", activation=\"relu\", skip_connection=False, edge_features_out=None):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # different aggregation functions\n",
        "        if aggregate == \"sum\":\n",
        "            self.aggregate = aggr.SumAggregation()\n",
        "        elif aggregate == \"mean\":\n",
        "            self.aggregate = aggr.MeanAggregation()\n",
        "        elif aggregate == \"max\":\n",
        "            self.aggregate = aggr.MaxAggregation()\n",
        "        elif aggregate == \"softmax\":\n",
        "            self.aggregate = aggr.SoftmaxAggregation(learn=True)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Aggregation '{aggregate}' not implemented\")\n",
        "\n",
        "        self.global_aggregate = aggr.MeanAggregation()\n",
        "\n",
        "        add_edge_fs = 1 if skip_connection else 0\n",
        "        edge_features_out = edge_features if edge_features_out is None else edge_features_out\n",
        "\n",
        "        # Graph Net Blocks (see https://arxiv.org/pdf/1806.01261.pdf)\n",
        "        self.edge_block = MLP([global_features + (edge_features + add_edge_fs) + (2 * node_features),\n",
        "                               hidden_size,\n",
        "                               edge_features_out],\n",
        "                              activation=activation)\n",
        "\n",
        "        self.node_block = MLP([global_features + edge_features_out + node_features,\n",
        "                               hidden_size,\n",
        "                               node_features],\n",
        "                              activation=activation)\n",
        "\n",
        "        # optional set of blocks for global GNN\n",
        "        self.global_block = None\n",
        "        if global_features > 0:\n",
        "            self.global_block = MLP([edge_features_out + node_features + global_features,\n",
        "                                     hidden_size,\n",
        "                                     global_features],\n",
        "                                    activation=activation)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, g=None):\n",
        "        row, col = edge_index\n",
        "\n",
        "        if self.global_block is not None:\n",
        "            assert g is not None, \"Need global features for global block\"\n",
        "\n",
        "            # run the edge update and aggregate features\n",
        "            edge_embedding = self.edge_block(torch.cat([torch.ones(x[row].shape[0], 1, device=x.device) * g,\n",
        "                                                        x[row], x[col], edge_attr], dim=1))\n",
        "            aggregation = self.aggregate(edge_embedding, row)\n",
        "\n",
        "\n",
        "            agg_features = torch.cat([torch.ones(x.shape[0], 1, device=x.device) * g, x, aggregation], dim=1)\n",
        "            node_embeddings = self.node_block(agg_features)\n",
        "\n",
        "            # aggregate over all edges and nodes (always mean)\n",
        "            mp_global_aggr = g\n",
        "            edge_aggregation_global = self.global_aggregate(edge_embedding)\n",
        "            node_aggregation_global = self.global_aggregate(node_embeddings)\n",
        "\n",
        "            # compute the new global embedding\n",
        "            # the old global feature is part of mp_global_aggr\n",
        "            global_embeddings = self.global_block(torch.cat([node_aggregation_global,\n",
        "                                                             edge_aggregation_global,\n",
        "                                                             mp_global_aggr], dim=1))\n",
        "\n",
        "            return edge_embedding, node_embeddings, global_embeddings\n",
        "\n",
        "        else:\n",
        "            # update edge features and aggregate\n",
        "            edge_embedding = self.edge_block(torch.cat([x[row], x[col], edge_attr], dim=1))\n",
        "            aggregation = self.aggregate(edge_embedding, row)\n",
        "            agg_features = torch.cat([x, aggregation], dim=1)\n",
        "            # update node features\n",
        "            node_embeddings = self.node_block(agg_features)\n",
        "            return edge_embedding, node_embeddings, None\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, width, layer_norm=False, activation=\"relu\", activate_final=False):\n",
        "        super().__init__()\n",
        "        width = list(filter(lambda x: x > 0, width))\n",
        "        assert len(width) >= 2, \"Need at least one layer in the network!\"\n",
        "\n",
        "        lls = nn.ModuleList()\n",
        "        for k in range(len(width)-1):\n",
        "            lls.append(nn.Linear(width[k], width[k+1], bias=True))\n",
        "            if k != (len(width)-2) or activate_final:\n",
        "                if activation == \"relu\":\n",
        "                    lls.append(nn.ReLU())\n",
        "                elif activation == \"tanh\":\n",
        "                    lls.append(nn.Tanh())\n",
        "                elif activation == \"leakyrelu\":\n",
        "                    lls.append(nn.LeakyReLU())\n",
        "                elif activation == \"sigmoid\":\n",
        "                    lls.append(nn.Sigmoid())\n",
        "                else:\n",
        "                    raise NotImplementedError(f\"Activation '{activation}' not implemented\")\n",
        "\n",
        "        if layer_norm:\n",
        "            lls.append(nn.LayerNorm(width[-1]))\n",
        "\n",
        "        self.m = nn.Sequential(*lls)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.m(x)\n",
        "\n",
        "\n",
        "class MP_Block(nn.Module):\n",
        "    # L@L.T matrix multiplication graph layer\n",
        "    # Aligns the computation of L@L.T - A with the learned updates\n",
        "    def __init__(self, skip_connections, first, last, edge_features, node_features, global_features, hidden_size, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # first and second aggregation\n",
        "        if \"aggregate\" in kwargs and kwargs[\"aggregate\"] is not None:\n",
        "            aggr = kwargs[\"aggregate\"] if len(kwargs[\"aggregate\"]) == 2 else kwargs[\"aggregate\"] * 2\n",
        "        else:\n",
        "            aggr = [\"mean\", \"sum\"]\n",
        "\n",
        "        act = kwargs[\"activation\"] if \"activation\" in kwargs else \"relu\"\n",
        "\n",
        "        edge_features_in = 1 if first else edge_features\n",
        "        edge_features_out = 1 if last else edge_features\n",
        "\n",
        "        # We use 2 graph nets in order to operate on the upper and lower triangular parts of the matrix\n",
        "        self.l1 = GraphNet(node_features=node_features, edge_features=edge_features_in, global_features=global_features,\n",
        "                           hidden_size=hidden_size, skip_connection=(not first and skip_connections),\n",
        "                           aggregate=aggr[0], activation=act, edge_features_out=edge_features)\n",
        "\n",
        "        self.l2 = GraphNet(node_features=node_features, edge_features=edge_features, global_features=global_features,\n",
        "                           hidden_size=hidden_size, aggregate=aggr[1], activation=act, edge_features_out=edge_features_out)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, global_features):\n",
        "        edge_embedding, node_embeddings, global_features = self.l1(x, edge_index, edge_attr, g=global_features)\n",
        "\n",
        "        # flip row and column indices\n",
        "        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n",
        "        edge_embedding, node_embeddings, global_features = self.l2(node_embeddings, edge_index, edge_embedding, g=global_features)\n",
        "\n",
        "        return edge_embedding, node_embeddings, global_features\n",
        "\n",
        "############################\n",
        "#         HELPERS          #\n",
        "############################\n",
        "def augment_features(data, skip_rhs=False):\n",
        "    # transform nodes to include more features\n",
        "\n",
        "    if skip_rhs:\n",
        "        # use instead notde position as an input feature!\n",
        "        data.x = torch.arange(data.x.size()[0], device=data.x.device).unsqueeze(1)\n",
        "\n",
        "    data = torch_geometric.transforms.LocalDegreeProfile()(data)\n",
        "\n",
        "    # diagonal dominance and diagonal decay from the paper\n",
        "    row, col = data.edge_index\n",
        "    diag = (row == col)\n",
        "    diag_elem = torch.abs(data.edge_attr[diag])\n",
        "    # remove diagonal elements by setting them to zero\n",
        "    non_diag_elem = data.edge_attr.clone()\n",
        "    non_diag_elem[diag] = 0\n",
        "\n",
        "    row_sums = aggr.SumAggregation()(torch.abs(non_diag_elem), row)\n",
        "    alpha = diag_elem / row_sums\n",
        "    row_dominance_feature = alpha / (alpha + 1)\n",
        "    row_dominance_feature = torch.nan_to_num(row_dominance_feature, nan=1.0)\n",
        "\n",
        "    # compute diagonal decay features\n",
        "    row_max = aggr.MaxAggregation()(torch.abs(non_diag_elem), row)\n",
        "    alpha = diag_elem / row_max\n",
        "    row_decay_feature = alpha / (alpha + 1)\n",
        "    row_decay_feature = torch.nan_to_num(row_decay_feature, nan=1.0)\n",
        "\n",
        "    data.x = torch.cat([data.x, row_dominance_feature, row_decay_feature], dim=1)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "class ToLowerTriangular(torch_geometric.transforms.BaseTransform):\n",
        "    def __init__(self, inplace=False):\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def __call__(self, data, order=None):\n",
        "        if not self.inplace:\n",
        "            data = data.clone()\n",
        "\n",
        "        # TODO: if order is given use that one instead\n",
        "        if order is not None:\n",
        "            raise NotImplementedError(\"Custom ordering not yet implemented...\")\n",
        "\n",
        "        # transform the data into lower triag graph\n",
        "        # this should be a data transformation (maybe?)\n",
        "        rows, cols = data.edge_index[0], data.edge_index[1]\n",
        "        fil = cols <= rows\n",
        "        l_index = data.edge_index[:, fil]\n",
        "        edge_embedding = data.edge_attr[fil]\n",
        "\n",
        "        data.edge_index, data.edge_attr = l_index, edge_embedding\n",
        "        return data"
      ],
      "metadata": {
        "id": "tB5GbXVa4xrJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Preconditioner:\n",
        "    def __init__(self, A, **kwargs):\n",
        "        self.breakdown = False\n",
        "        self.nnz = 0\n",
        "        self.time = 0\n",
        "        self.n = kwargs.get(\"n\", 0)\n",
        "\n",
        "    def timed_setup(self, A, **kwargs):\n",
        "        start = time_function()\n",
        "        self.setup(A, **kwargs)\n",
        "        stop = time_function()\n",
        "        self.time = stop - start\n",
        "\n",
        "    def get_inverse(self):\n",
        "        ones = torch.ones(self.n)\n",
        "        offset = torch.zeros(1).to(torch.int64)\n",
        "\n",
        "        I = torch.sparse.spdiags(ones, offset, (self.n, self.n))\n",
        "        I = I.to(torch.float64)\n",
        "\n",
        "        return I\n",
        "\n",
        "    def get_p_matrix(self):\n",
        "        return self.get_inverse()\n",
        "\n",
        "    def check_breakdown(self, P):\n",
        "        if np.isnan(np.min(P)):\n",
        "            self.breakdown = True\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return x\n",
        "\n",
        "class LearnedPreconditioner(Preconditioner):\n",
        "    def __init__(self, data, model, **kwargs):\n",
        "        super().__init__(data, **kwargs)\n",
        "\n",
        "        self.model = model\n",
        "        self.spd = isinstance(model, NeuralIF)\n",
        "\n",
        "        self.timed_setup(data, **kwargs)\n",
        "\n",
        "        # # count non‐zeros in a torch Tensor / sparse tensor\n",
        "        # def count_nnz(tensor):\n",
        "        #     if tensor.layout == torch.sparse_coo:\n",
        "        #         # number of nonzero entries in a sparse_coo_tensor\n",
        "        #         return int(tensor._values().numel())\n",
        "        #     else:\n",
        "        #         # dense tensor: count != 0\n",
        "        #         return int((tensor != 0).sum().item())\n",
        "\n",
        "        # if self.spd:\n",
        "        #     self.nnz = count_nnz(self.L)\n",
        "        # else:\n",
        "        #     nnz_L = count_nnz(self.L)\n",
        "        #     nnz_U = count_nnz(self.U)\n",
        "        #     # subtract the diagonal entries once:\n",
        "        #     self.nnz = nnz_L + nnz_U - int(data.x.size(0))\n",
        "\n",
        "        if self.spd:\n",
        "            self.nnz = self.L.nnz\n",
        "        else:\n",
        "            self.nnz = self.L.nnz + self.U.nnz - data.x.shape[0]\n",
        "\n",
        "    def setup(self, data, **kwargs):\n",
        "        L, U, _ = self.model(data)\n",
        "\n",
        "        self.L = L.to(\"cpu\").to(torch.float64)\n",
        "        self.U = U.to(\"cpu\").to(torch.float64)\n",
        "\n",
        "    def get_inverse(self):\n",
        "        L_inv = torch.inverse(self.L.to_dense())\n",
        "        U_inv = torch.inverse(self.U.to_dense())\n",
        "\n",
        "        return U_inv@L_inv\n",
        "\n",
        "    def get_p_matrix(self):\n",
        "        return self.L@self.U\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return fb_solve(self.L, self.U, x, unit_upper=not self.spd)\n",
        "\n",
        "\n",
        "def fb_solve(L, U, r, unit_lower=False, unit_upper=False):\n",
        "    print(L)\n",
        "    y = L.solve_triangular(upper=False, unit=unit_lower, b=r)\n",
        "    z = U.solve_triangular(upper=True, unit=unit_upper, b=y)\n",
        "    return z\n",
        "\n",
        "time_function = lambda: time.perf_counter()"
      ],
      "metadata": {
        "id": "bx6j4iRY-XYl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions\n",
        "@torch.no_grad()\n",
        "def validate(model, validation_loader, solve=False, solver=\"cg\"):\n",
        "    model.eval()\n",
        "    acc_loss = 0.0\n",
        "    num_loss = 0\n",
        "    acc_solver_iters = 0.0\n",
        "\n",
        "    for data in validation_loader:\n",
        "        data = data.to(device)\n",
        "        A, b = graph_to_matrix(data)\n",
        "\n",
        "        if solve:\n",
        "            preconditioner = LearnedPreconditioner(data, model)\n",
        "            print(preconditioner)\n",
        "            A_cpu = A.cpu().double()\n",
        "            b_cpu = b.cpu().double()\n",
        "            x0 = None\n",
        "\n",
        "            start = time.time()\n",
        "            if solver == \"cg\":\n",
        "                iters, x_hat = preconditioned_conjugate_gradient(\n",
        "                    A_cpu, b_cpu, M=preconditioner, x0=x0,\n",
        "                    rtol=1e-6, max_iter=1000\n",
        "                )\n",
        "            else:\n",
        "                iters, x_hat = gmres(\n",
        "                    A_cpu, b_cpu, M=preconditioner, x0=x0,\n",
        "                    atol=1e-6, max_iter=1000, left=False\n",
        "                )\n",
        "            acc_solver_iters += len(iters) - 1\n",
        "        else:\n",
        "            output, _, _ = model(data)\n",
        "            # l = frobenius_loss(output, A)\n",
        "            l = loss(data, output, config=\"frobenius\")\n",
        "            acc_loss += l.item()\n",
        "            num_loss += 1\n",
        "\n",
        "    if solve:\n",
        "        avg_iters = acc_solver_iters / len(validation_loader)\n",
        "        print(f\"Validation iterations: {avg_iters:.2f}\")\n",
        "        return avg_iters\n",
        "    else:\n",
        "        avg_loss = acc_loss / num_loss\n",
        "        print(f\"Validation loss: {avg_loss:.4f}\")\n",
        "        return avg_loss"
      ],
      "metadata": {
        "id": "bRETenOFREJj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NeuralIF model"
      ],
      "metadata": {
        "id": "6pz6E3na4ruX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralIF(nn.Module):\n",
        "    # Neural Incomplete factorization\n",
        "    def __init__(self, drop_tol=0, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.global_features = kwargs[\"global_features\"]\n",
        "        self.latent_size = kwargs[\"latent_size\"]\n",
        "        # node features are augmented with local degree profile\n",
        "        self.augment_node_features = kwargs[\"augment_nodes\"]\n",
        "\n",
        "        num_node_features = 8 if self.augment_node_features else 1\n",
        "        message_passing_steps = kwargs[\"message_passing_steps\"]\n",
        "\n",
        "        # edge feature representation in the latent layers\n",
        "        edge_features = kwargs.get(\"edge_features\", 1)\n",
        "\n",
        "        self.skip_connections = kwargs[\"skip_connections\"]\n",
        "\n",
        "        self.mps = torch.nn.ModuleList()\n",
        "        for l in range(message_passing_steps):\n",
        "            # skip connections are added to all layers except the first one\n",
        "            self.mps.append(MP_Block(skip_connections=self.skip_connections,\n",
        "                                     first=l==0,\n",
        "                                     last=l==(message_passing_steps-1),\n",
        "                                     edge_features=edge_features,\n",
        "                                     node_features=num_node_features,\n",
        "                                     global_features=self.global_features,\n",
        "                                     hidden_size=self.latent_size,\n",
        "                                     activation=kwargs[\"activation\"],\n",
        "                                     aggregate=kwargs[\"aggregate\"]))\n",
        "\n",
        "        # node decodings\n",
        "        self.node_decoder = MLP([num_node_features, self.latent_size, 1]) if kwargs[\"decode_nodes\"] else None\n",
        "\n",
        "        # diag-aggregation for normalization of rows\n",
        "        self.normalize_diag = kwargs[\"normalize_diag\"] if \"normalize_diag\" in kwargs else False\n",
        "        self.diag_aggregate = aggr.SumAggregation()\n",
        "\n",
        "        # normalization\n",
        "        self.graph_norm = pyg.norm.GraphNorm(num_node_features) if (\"graph_norm\" in kwargs and kwargs[\"graph_norm\"]) else None\n",
        "\n",
        "        # drop tolerance and additional fill-ins and more sparsity\n",
        "        self.tau = drop_tol\n",
        "        self.two = kwargs.get(\"two_hop\", False)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # ! data could be batched here...(not implemented)\n",
        "\n",
        "        if self.augment_node_features:\n",
        "            data = augment_features(data, skip_rhs=True)\n",
        "\n",
        "        # add additional edges to the data\n",
        "        if self.two:\n",
        "            data = TwoHop()(data)\n",
        "\n",
        "        # * in principle it is possible to integrate reordering here.\n",
        "\n",
        "        data = ToLowerTriangular()(data)\n",
        "\n",
        "        # get the input data\n",
        "        edge_embedding = data.edge_attr\n",
        "        l_index = data.edge_index\n",
        "\n",
        "        if self.graph_norm is not None:\n",
        "            node_embedding = self.graph_norm(data.x, batch=data.batch)\n",
        "        else:\n",
        "            node_embedding = data.x\n",
        "\n",
        "        # copy the input data (only edges of original matrix A)\n",
        "        a_edges = edge_embedding.clone()\n",
        "\n",
        "        if self.global_features > 0:\n",
        "            global_features = torch.zeros((1, self.global_features), device=data.x.device, requires_grad=False)\n",
        "            # feature ideas: nnz, 1-norm, inf-norm col/row var, min/max variability, avg distances to nnz\n",
        "        else:\n",
        "            global_features = None\n",
        "\n",
        "        # compute the output of the network\n",
        "        for i, layer in enumerate(self.mps):\n",
        "            if i != 0 and self.skip_connections:\n",
        "                edge_embedding = torch.cat([edge_embedding, a_edges], dim=1)\n",
        "\n",
        "            edge_embedding, node_embedding, global_features = layer(node_embedding, l_index, edge_embedding, global_features)\n",
        "\n",
        "        # transform the output into a matrix\n",
        "        return self.transform_output_matrix(node_embedding, l_index, edge_embedding, a_edges)\n",
        "\n",
        "    def transform_output_matrix(self, node_x, edge_index, edge_values, a_edges):\n",
        "        # force diagonal to be positive\n",
        "        diag = edge_index[0] == edge_index[1]\n",
        "\n",
        "        # normalize diag such that it has zero residual\n",
        "        if self.normalize_diag:\n",
        "            # copy the diag of matrix A\n",
        "            a_diag = a_edges[diag]\n",
        "\n",
        "            # compute the row norm\n",
        "            square_values = torch.pow(edge_values, 2)\n",
        "            aggregated = self.diag_aggregate(square_values, edge_index[0])\n",
        "\n",
        "            # now, we renormalize the edge values such that they are the square root of the original value...\n",
        "            edge_values = torch.sqrt(a_diag[edge_index[0]]) * edge_values / torch.sqrt(aggregated[edge_index[0]])\n",
        "\n",
        "        else:\n",
        "            # otherwise, just take the edge values as they are...\n",
        "            # but take the square root as it is numerically better\n",
        "            # edge_values[diag] = torch.exp(edge_values[diag])\n",
        "            edge_values[diag] = torch.sqrt(torch.exp(edge_values[diag]))\n",
        "\n",
        "        # node decoder\n",
        "        node_output = self.node_decoder(node_x).squeeze() if self.node_decoder is not None else None\n",
        "\n",
        "        # ! this if should only be activated when the model is in production!!\n",
        "        if torch.is_inference_mode_enabled():\n",
        "\n",
        "            # we can decide to remove small elements during inference from the preconditioner matrix\n",
        "            if self.tau != 0:\n",
        "                small_value = (torch.abs(edge_values) <= self.tau).squeeze()\n",
        "\n",
        "                # small value and not diagonal\n",
        "                elems = torch.logical_and(small_value, torch.logical_not(diag))\n",
        "\n",
        "                # might be able to do this easily!\n",
        "                edge_values[elems] = 0\n",
        "\n",
        "                # remove zeros from the sparse representation\n",
        "                filt = (edge_values != 0).squeeze()\n",
        "                edge_values = edge_values[filt]\n",
        "                edge_index = edge_index[:, filt]\n",
        "\n",
        "            # ! this is the way to go!!\n",
        "            # Doing pytorch -> scipy -> numml is a lot faster than pytorch -> numml on CPU\n",
        "            # On GPU it is faster to go to pytorch -> numml -> CPU\n",
        "\n",
        "            # convert to scipy sparse matrix\n",
        "            # m = to_scipy_sparse_matrix(edge_index, matrix_values)\n",
        "            m = torch.sparse_coo_tensor(edge_index, edge_values.squeeze(),\n",
        "                                        size=(node_x.size()[0], node_x.size()[0]))\n",
        "                                        # type=torch.double)\n",
        "\n",
        "            # produce L and U seperatly\n",
        "            l = SparseCSRTensor(m)\n",
        "            u = SparseCSRTensor(m.T)\n",
        "\n",
        "            return l, u, node_output\n",
        "\n",
        "        else:\n",
        "            # For training and testing (computing regular losses for examples.)\n",
        "            # does not need to be performance optimized!\n",
        "            # use torch sparse directly\n",
        "            t = torch.sparse_coo_tensor(edge_index, edge_values.squeeze(),\n",
        "                                        size=(node_x.size()[0], node_x.size()[0]))\n",
        "\n",
        "            # normalized l1 norm is best computed here!\n",
        "            # l2_nn = torch.linalg.norm(edge_values, ord=2)\n",
        "            l1_penalty = torch.sum(torch.abs(edge_values)) / len(edge_values)\n",
        "\n",
        "            return t, l1_penalty, node_output\n"
      ],
      "metadata": {
        "id": "fo19YfVkW3cT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training"
      ],
      "metadata": {
        "id": "C_ySuevTbPWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Training Configuration"
      ],
      "metadata": {
        "id": "p9Rge5QlbVmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"name\": \"experiment_1\",\n",
        "    \"save\": True,\n",
        "    \"seed\": 42,\n",
        "    \"n\": 0,\n",
        "    \"batch_size\": 1,\n",
        "    \"num_epochs\": 100,\n",
        "    \"dataset\": \"random\",\n",
        "    \"loss\": \"frobenius\",\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"regularizer\": 0.0,\n",
        "    \"scheduler\": False,\n",
        "    \"model\": \"neuralif\",\n",
        "    \"normalize\": False,\n",
        "    \"latent_size\": 8,\n",
        "    \"message_passing_steps\": 3,\n",
        "    \"decode_nodes\": False,\n",
        "    \"normalize_diag\": False,\n",
        "    \"aggregate\": [\"mean\", \"sum\"],\n",
        "    \"activation\": \"relu\",\n",
        "    \"skip_connections\": True,\n",
        "    \"augment_nodes\": False,\n",
        "    \"global_features\": 0,\n",
        "    \"edge_features\": 1,\n",
        "    \"graph_norm\": False,\n",
        "    \"two_hop\": False,\n",
        "    \"num_neighbors\": [15, 10]  # number of neighbours to sample in each hop (GraphSAGE sampling)\n",
        "}\n",
        "\n",
        "# Prepare output folder\n",
        "if config[\"name\"]:\n",
        "    folder = f\"results/{config['name']}\"\n",
        "else:\n",
        "    folder = datetime.datetime.now().strftime(\"results/%Y-%m-%d_%H-%M-%S\")\n",
        "if config[\"save\"]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    save_dict_to_file(config, os.path.join(folder, \"config.json\"))\n"
      ],
      "metadata": {
        "id": "Og3JzHyyQ5-x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed for reproducibility\n",
        "torch_geometric.seed_everything(config[\"seed\"])\n",
        "\n",
        "# Select model\n",
        "model_args = {k: config[k] for k in [\n",
        "    \"latent_size\", \"message_passing_steps\", \"skip_connections\",\n",
        "    \"augment_nodes\", \"global_features\", \"decode_nodes\",\n",
        "    \"normalize_diag\", \"activation\", \"aggregate\", \"graph_norm\",\n",
        "    \"two_hop\", \"edge_features\", \"normalize\"\n",
        "] if k in config}\n",
        "\n",
        "use_gmres = False\n",
        "if config[\"model\"] in (\"nif\", \"neuralif\", \"inf\"):\n",
        "    model = NeuralIF(**model_args)\n",
        "else:\n",
        "    raise ValueError(\"Unknown model type\")\n",
        "\n",
        "model.to(device)\n",
        "print(\"Number of parameters:\", count_parameters(model))\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.5, patience=20\n",
        ")"
      ],
      "metadata": {
        "id": "tJnpsDJBRzJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e99327b-711a-4e6c-8dc5-5dda278e8142"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set DataLoader\n",
        "Run only 1 cell from the following"
      ],
      "metadata": {
        "id": "cB2pRLKG1WjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader using NeighborSampler (GraphSAGE-inspired)\n",
        "- Random sampling of nodes at each layer to form a node's local neighbourhood"
      ],
      "metadata": {
        "id": "F8MkpyO6xvfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import NeighborSampler\n",
        "from torch.utils.data import IterableDataset\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import DataLoader\n",
        "import torch_sparse, torch_scatter\n",
        "\n",
        "# get list of all files from directory in .pt format. each file represents 1 graph\n",
        "train_dataset = FolderDataset(f\"./data/Random/train/\", n=config[\"n\"], graph=True, size=None)\n",
        "train_graphs   = [torch.load(path, weights_only=False) for path in train_dataset.files]\n",
        "big_train_data = Batch.from_data_list(train_graphs)\n",
        "\n",
        "# transform each sampler batch into a Data object\n",
        "def to_data(batch_size, n_id, adjs):\n",
        "    # Collect the node features for all participating nodes:\n",
        "    x_sub = big_train_data.x[n_id]\n",
        "\n",
        "    # Gather edges & edge‐attrs from each hop:\n",
        "    rows, cols, eids = [], [], []\n",
        "    for edge_index, e_id, size in adjs:\n",
        "        rows.append(edge_index[0])\n",
        "        cols.append(edge_index[1])\n",
        "        eids.append(e_id)\n",
        "    row = torch.cat(rows, dim=0)\n",
        "    col = torch.cat(cols, dim=0)\n",
        "    eid = torch.cat(eids, dim=0)\n",
        "\n",
        "    edge_index_sub = torch.stack([row, col], dim=0)\n",
        "    edge_attr_sub  = big_train_data.edge_attr[eid]\n",
        "\n",
        "    data = Data(\n",
        "        x          = x_sub,\n",
        "        edge_index = edge_index_sub,\n",
        "        edge_attr  = edge_attr_sub,\n",
        "    )\n",
        "    data.n = x_sub.size(0)            # if your model reads data.n\n",
        "    return data\n",
        "\n",
        "# build neighbour sampler while transforming all training entries to the Data object\n",
        "train_loader = NeighborSampler(               # implementation of abstract class DataLoader\n",
        "    edge_index   = big_train_data.edge_index,\n",
        "    sizes        = config[\"num_neighbors\"],\n",
        "    node_idx     = None,                      # sample seeds from all nodes\n",
        "    num_nodes    = big_train_data.num_nodes,\n",
        "    return_e_id  = True,                      # we need the e_id to slice edge_attr\n",
        "    transform    = to_data,                   # turn each sample into Data\n",
        "    batch_size   = config[\"batch_size\"],      # # of seeds per iteration\n",
        "    shuffle      = True,\n",
        "    num_workers  = 4,\n",
        "    pin_memory   = True,\n",
        ")\n",
        "\n",
        "first_sample = next(iter(train_loader))\n",
        "print(type(first_sample))    # torch_geometric.data.Data\n",
        "print(first_sample)          # Data object with format x, edge_index, edge_attr, n, etc.\n",
        "print(len(train_loader))\n",
        "\n",
        "# load the full graph for the validation dataloader\n",
        "validation_loader = get_dataloader(config[\"dataset\"], config[\"n\"], batch_size=1, spd=(not gmres), mode=\"val\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsP6Pt5Xxmar",
        "outputId": "ae513d3c-11de-4f39-8c1c-86e07a703e73"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch_geometric.data.data.Data'>\n",
            "Data(x=[1, 1], edge_index=[2, 2], edge_attr=[2, 1], n=1)\n",
            "100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader for full graph (Original dataloader)"
      ],
      "metadata": {
        "id": "TSQKWRx5xvz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. retrieve the FolderDataset object for each of train and validation loader based on .pt files\n",
        "# 2. pass the FolderDataset object into torch.util's DataLoader as the dataset field\n",
        "# 3. return this DataLoader object\n",
        "\n",
        "# the loader below passes train_dataset directly to torch.util's DataLoader class\n",
        "\n",
        "train_loader = get_dataloader(config[\"dataset\"], config[\"n\"], config[\"batch_size\"],\n",
        "                                  spd=not gmres, mode=\"train\")\n",
        "\n",
        "print(train_loader.dataset[0])\n",
        "print(len(train_loader))\n",
        "\n",
        "validation_loader = get_dataloader(config[\"dataset\"], config[\"n\"], 1, spd=(not gmres), mode=\"val\")"
      ],
      "metadata": {
        "id": "vknOPTMW-9MU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f392bc6d-e0cb-47f6-cd39-626e632bd32c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[1000, 1], edge_index=[2, 2038], edge_attr=[2038, 1], s=[1000], n=1000)\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "wdHEnL851cFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import add_self_loops\n",
        "\n",
        "\n",
        "# training loop\n",
        "best_val = float(\"inf\")\n",
        "logger = TrainResults(folder)\n",
        "total_it = 0\n",
        "\n",
        "for epoch in range(config[\"num_epochs\"]):\n",
        "    running_loss = 0.0\n",
        "    start_epoch = time.perf_counter()\n",
        "\n",
        "    for data in train_loader:\n",
        "        total_it += 1\n",
        "        model.train()\n",
        "\n",
        "        start = time.perf_counter()\n",
        "        data = data.to(device)\n",
        "\n",
        "        ### resolving the unmatching dimension bug for NeighborSampler class\n",
        "        # 1) override n properly\n",
        "        data.n = int(data.x.size(0))\n",
        "\n",
        "        # 2) add self-loops so each node has at least one incoming edge\n",
        "        data.edge_index, data.edge_attr = add_self_loops(\n",
        "            data.edge_index,\n",
        "            data.edge_attr,\n",
        "            fill_value=0.0,\n",
        "            num_nodes=data.n\n",
        "        )\n",
        "        ###\n",
        "\n",
        "        # print(f\"Input training data to the model is {data}\")\n",
        "        output, reg, _ = model(data)\n",
        "        # print(f\"Output from the model is {output} and reg term is {reg}\")\n",
        "\n",
        "        l = loss(output, data, c=reg, config=config[\"loss\"])\n",
        "        l.backward()\n",
        "\n",
        "        # gradient clipping or manual norm\n",
        "        if config[\"gradient_clipping\"]:\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                model.parameters(), config[\"gradient_clipping\"]\n",
        "            )\n",
        "        else:\n",
        "            total_norm = sum(\n",
        "                p.grad.detach().data.norm(2).item() ** 2\n",
        "                for p in model.parameters() if p.grad is not None\n",
        "            )\n",
        "            grad_norm = (total_norm ** 0.5) / config[\"batch_size\"]\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += l.item()\n",
        "        logger.log(l.item(), grad_norm, time.perf_counter() - start)\n",
        "\n",
        "        # periodic validation\n",
        "        if total_it % 1000 == 0:\n",
        "            val_metric = validate(\n",
        "                model, validation_loader, solve=True,\n",
        "                solver=\"gmres\" if use_gmres else \"cg\"\n",
        "            )\n",
        "            logger.log_val(None, val_metric)\n",
        "            if val_metric < best_val:\n",
        "                best_val = val_metric\n",
        "                if config[\"save\"]:\n",
        "                    torch.save(model.state_dict(), f\"{folder}/best_model.pt\")\n",
        "\n",
        "    epoch_time = time.perf_counter() - start_epoch\n",
        "    print(f\"Epoch {epoch+1} — loss: {running_loss/len(train_loader):.4f}, time: {epoch_time:.1f}s\")\n",
        "    if config[\"save\"]:\n",
        "        torch.save(model.state_dict(), f\"{folder}/model_epoch{epoch+1}.pt\")\n"
      ],
      "metadata": {
        "id": "sMSaRR7cSMFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "2d546c92-07c2-4772-b934-7c2a65f8a48b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 — loss: 87.6323, time: 2.2s\n",
            "Epoch 2 — loss: 63.8363, time: 2.7s\n",
            "Epoch 3 — loss: 47.7741, time: 2.9s\n",
            "Epoch 4 — loss: 38.9555, time: 2.8s\n",
            "Epoch 5 — loss: 33.1676, time: 2.7s\n",
            "Epoch 6 — loss: 29.2067, time: 2.2s\n",
            "Epoch 7 — loss: 26.4143, time: 4.0s\n",
            "Epoch 8 — loss: 24.6473, time: 2.9s\n",
            "Epoch 9 — loss: 23.4678, time: 2.2s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Tensor' object has no attribute 'nnz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1869043708>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# periodic validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_it\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             val_metric = validate(\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gmres\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_gmres\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-1259403937>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, validation_loader, solve, solver)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mpreconditioner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearnedPreconditioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreconditioner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mA_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-1577741011>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, model, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'nnz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save results\n",
        "if config[\"save\"]:\n",
        "    logger.save_results()\n",
        "    torch.save(model.to(torch.float).state_dict(), f\"{folder}/final_model.pt\")\n"
      ],
      "metadata": {
        "id": "vom7sud2SSpt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test printout\n",
        "print(\"Best validation performance:\", best_val)"
      ],
      "metadata": {
        "id": "5JqtkgTZSaSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}