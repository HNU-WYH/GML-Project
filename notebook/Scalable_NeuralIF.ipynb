{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scalable GNN–Based Preconditioners for Conjugate Gradient Methods\n",
        "**Authors: Nicholas Tan Yun Yu, Low Jun Yu, Yuhan Wu**\n",
        "\n",
        "This project was inspired by [NeuralIF](https://arxiv.org/abs/2305.16368).\n",
        "\n",
        "**Summary**: The authors come up with a novel message-passing GNN block that is used by the network to predict efficient preconditioners to solve sparse linear systems. These preconditioners are tested using the preconditioned conjugate gradient (CG) method, which make the algorithm converge faster than other state-of-the-art preconditioners.\n",
        "\n",
        "**Motivation**: Modern data-driven and physics-based applications frequently force us to deal with dense matrices. Therefore, we hope to show that the message-passing GNN block can learn effective preconditioners for these scaled up fields. An example of a machine learning problem that could benefit from this is Gaussian Processes, which makes use of a dense kernel function as such: (some image)\n",
        "\n",
        "**The problem**: Scaling the problem to dense matrices is nontrivial. The Coates graph representation has 1 node per row/column, and one edge only for each nonzero entry in A. For a dense n*n matrix, that graph becomes complete – with n^2 edges – so both memory and compute blow up to O(n^2).\n",
        "\n",
        "**Research direction**: Implement an edge-regression GNN that can work on dense matrices. We can achieve this using sampling techniques such as GraphSAGE and Cluster-GCN."
      ],
      "metadata": {
        "id": "J_CMa5FedgDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installation & Setup"
      ],
      "metadata": {
        "id": "XrqVh2BF7LhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load files from google drive"
      ],
      "metadata": {
        "id": "-4MVBD1eXd8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSuii7-phJYZ",
        "outputId": "2a5349a0-ef30-44ef-c2bd-6335b4a92f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add directory to python's path\n",
        "# This directory path should lead straight to the root of the project\n",
        "# Ensure that the project's root directory has the folders \"krylov\", \"apps\" and \"neuralif\"\n",
        "#   that has the files contained in https://github.com/paulhausner/neural-incomplete-factorization/tree/main\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CS4350/project/')"
      ],
      "metadata": {
        "id": "tbuq9axkgIj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package installation"
      ],
      "metadata": {
        "id": "ehpIKqQaX36-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q torch_geometric\n",
        "%pip install pyg-lib -f https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
        "!pip3 install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "WuLYpuGUDMoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0322f40c-0052-4410-a26c-1f8f1e9c24a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLooking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyg-lib\n",
            "Successfully installed pyg-lib-0.4.0+pt26cu124\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nicknytko/numml.git\n",
        "!pip3 install -e numml/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KGYzsShHXY_",
        "outputId": "bdc4467c-ce72-41d4-c929-8ece3b85fcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'numml'...\n",
            "remote: Enumerating objects: 673, done.\u001b[K\n",
            "remote: Counting objects: 100% (311/311), done.\u001b[K\n",
            "remote: Compressing objects: 100% (140/140), done.\u001b[K\n",
            "remote: Total 673 (delta 232), reused 213 (delta 169), pack-reused 362 (from 1)\u001b[K\n",
            "Receiving objects: 100% (673/673), 1.28 MiB | 5.25 MiB/s, done.\n",
            "Resolving deltas: 100% (414/414), done.\n",
            "Obtaining file:///content/numml\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from numml==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from numml==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->numml==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->numml==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->numml==0.1.0) (3.0.2)\n",
            "Building wheels for collected packages: numml\n",
            "  Building editable for numml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numml: filename=numml-0.1.0-0.editable-cp311-cp311-linux_x86_64.whl size=4243 sha256=e07a38b34c3699073023abfec7775e897291d2c3cab7bcb93adeafeab5808f02\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-423y_kes/wheels/e4/c7/60/5c5dbff4a2bca3147d0cd3159ffd391d2cc28ebe1c9555eb4c\n",
            "Successfully built numml\n",
            "Installing collected packages: numml\n",
            "Successfully installed numml-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "HgiuVFCFX9Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "import pprint\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as pyg\n",
        "from torch_geometric.nn import aggr\n",
        "from torch_geometric.utils import to_scipy_sparse_matrix\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.data import Batch\n",
        "from scipy.sparse import tril, coo_matrix\n",
        "\n",
        "from apps.data import get_dataloader, graph_to_matrix, matrix_to_graph, FolderDataset\n",
        "from neuralif.utils import (\n",
        "    count_parameters, save_dict_to_file,\n",
        "    condition_number, eigenval_distribution, gershgorin_norm,\n",
        "    TwoHop\n",
        ")\n",
        "from neuralif.logger import TrainResults, TestResults\n",
        "from neuralif.loss import loss\n",
        "\n",
        "from krylov.cg import preconditioned_conjugate_gradient\n",
        "from krylov.gmres import gmres\n",
        "\n",
        "# import from self-curated numml file\n",
        "# from numml import SparseCSRTensor"
      ],
      "metadata": {
        "id": "c3uK7LjaQoMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set GPU"
      ],
      "metadata": {
        "id": "1BzKAAbyYE59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDfXtM3xQzwJ",
        "outputId": "2e3f6c83-787a-46a7-c21f-6d8859fa08b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset generation"
      ],
      "metadata": {
        "id": "zmYSP8cAZFaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "cA9OMUsXaQKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sparse_random(n, alpha=1e-4, random_state=0, sol=False, ood=False):\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    if alpha is None:\n",
        "        alpha = rng.uniform(1e-4, 1e-2)\n",
        "    sparsity = 10e-4  # this is 1% sparsity for n = 10 000\n",
        "\n",
        "    if ood:\n",
        "        factor = rng.uniform(0.22, 2.2)\n",
        "        sparsity *= factor\n",
        "\n",
        "    nnz = int(sparsity * n ** 2)\n",
        "    rows = [rng.randint(0, n) for _ in range(nnz)]\n",
        "    cols = [rng.randint(0, n) for _ in range(nnz)]\n",
        "    uniques = set(zip(rows, cols))\n",
        "    rows, cols = zip(*uniques)\n",
        "    vals = rng.normal(0, 1, size=len(cols))\n",
        "\n",
        "    M = coo_matrix((vals, (rows, cols)), shape=(n, n))\n",
        "    I = scipy.sparse.identity(n)\n",
        "    A = (M @ M.T) + alpha * I # create spd matrix\n",
        "    print(f\"Generated matrix with {100 * (A.nnz / n**2):.2f}% non-zeros ({A.nnz} entries)\")\n",
        "\n",
        "    b = rng.uniform(0, 1, size=n)\n",
        "    x = None\n",
        "    if sol:\n",
        "        x, _ = scipy.sparse.linalg.cg(A, b)\n",
        "    return A, x, b\n",
        "\n",
        "def create_dataset(n, samples, alpha=1e-2, graph=True, rs=0, mode='train', solution=False):\n",
        "    if mode != 'train' and rs == 0:\n",
        "        raise ValueError('`rs` must be non-zero for val/test to avoid overlap')\n",
        "\n",
        "    print(f\"Creating {samples} samples for '{mode}' set (n={n})\")\n",
        "    for sam in range(samples):\n",
        "        A, x, b = generate_sparse_random(\n",
        "            n, alpha=alpha, random_state=rs + sam,\n",
        "            sol=solution, ood=(mode == \"test_ood\")\n",
        "        )\n",
        "        if graph:\n",
        "            g = matrix_to_graph(A, b)\n",
        "            if x is not None:\n",
        "                g.s = torch.tensor(x, dtype=torch.float)\n",
        "            g.n = n\n",
        "            torch.save(g, f'./data/Random/{mode}/{n}_{sam}.pt')\n",
        "        else:\n",
        "            scipy.sparse.save_npz(f'./data/Random/{mode}/{n}_{sam}.npz', A)\n",
        "            np.savez(f'./data/Random/{mode}/{n}_{sam}.npz', A=A, b=b, x=x)\n"
      ],
      "metadata": {
        "id": "JKMq525PZEId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Train, Validation and Test datasets"
      ],
      "metadata": {
        "id": "2Coq9OGHdUm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure target folders exist\n",
        "for split in ['train', 'val', 'test']:\n",
        "    os.makedirs(f'./data/Random/{split}', exist_ok=True)\n",
        "\n",
        "# parameters\n",
        "n = 10_00\n",
        "alpha = 1e-4\n",
        "\n",
        "# generate\n",
        "create_dataset(n, samples=100, alpha=alpha, mode='train', rs=0, graph=True, solution=True)\n",
        "create_dataset(n, samples=5, alpha=alpha, mode='val', rs=10000, graph=True, solution=False)\n",
        "create_dataset(n, samples=20, alpha=alpha, mode='test', rs=103600, graph=True, solution=False)\n"
      ],
      "metadata": {
        "id": "lWJ7E9ZEaCQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f5e7be-b1c2-4028-df86-50a3f97736cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating 100 samples for 'train' set (n=1000)\n",
            "Generated matrix with 0.21% non-zeros (2078 entries)\n",
            "Generated matrix with 0.21% non-zeros (2072 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1978 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (1962 entries)\n",
            "Generated matrix with 0.20% non-zeros (2032 entries)\n",
            "Generated matrix with 0.21% non-zeros (2066 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (2008 entries)\n",
            "Generated matrix with 0.20% non-zeros (2018 entries)\n",
            "Generated matrix with 0.20% non-zeros (2040 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (2010 entries)\n",
            "Generated matrix with 0.20% non-zeros (2006 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.19% non-zeros (1918 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1964 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1962 entries)\n",
            "Generated matrix with 0.20% non-zeros (2042 entries)\n",
            "Generated matrix with 0.20% non-zeros (2010 entries)\n",
            "Generated matrix with 0.20% non-zeros (1982 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n",
            "Generated matrix with 0.20% non-zeros (1988 entries)\n",
            "Generated matrix with 0.21% non-zeros (2072 entries)\n",
            "Generated matrix with 0.19% non-zeros (1950 entries)\n",
            "Generated matrix with 0.20% non-zeros (1960 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1974 entries)\n",
            "Generated matrix with 0.20% non-zeros (1984 entries)\n",
            "Generated matrix with 0.19% non-zeros (1904 entries)\n",
            "Generated matrix with 0.20% non-zeros (2044 entries)\n",
            "Generated matrix with 0.20% non-zeros (2044 entries)\n",
            "Generated matrix with 0.20% non-zeros (1976 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (2008 entries)\n",
            "Generated matrix with 0.21% non-zeros (2108 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (1974 entries)\n",
            "Generated matrix with 0.19% non-zeros (1944 entries)\n",
            "Generated matrix with 0.20% non-zeros (2006 entries)\n",
            "Generated matrix with 0.20% non-zeros (1982 entries)\n",
            "Generated matrix with 0.21% non-zeros (2086 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (1988 entries)\n",
            "Generated matrix with 0.21% non-zeros (2054 entries)\n",
            "Generated matrix with 0.20% non-zeros (2018 entries)\n",
            "Generated matrix with 0.20% non-zeros (2000 entries)\n",
            "Generated matrix with 0.20% non-zeros (2018 entries)\n",
            "Generated matrix with 0.20% non-zeros (2026 entries)\n",
            "Generated matrix with 0.20% non-zeros (1974 entries)\n",
            "Generated matrix with 0.19% non-zeros (1938 entries)\n",
            "Generated matrix with 0.21% non-zeros (2062 entries)\n",
            "Generated matrix with 0.19% non-zeros (1948 entries)\n",
            "Generated matrix with 0.20% non-zeros (2008 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (2000 entries)\n",
            "Generated matrix with 0.20% non-zeros (1964 entries)\n",
            "Generated matrix with 0.20% non-zeros (1972 entries)\n",
            "Generated matrix with 0.20% non-zeros (1998 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (2002 entries)\n",
            "Generated matrix with 0.20% non-zeros (1984 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n",
            "Generated matrix with 0.21% non-zeros (2050 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2012 entries)\n",
            "Generated matrix with 0.19% non-zeros (1936 entries)\n",
            "Generated matrix with 0.20% non-zeros (2016 entries)\n",
            "Generated matrix with 0.20% non-zeros (2026 entries)\n",
            "Generated matrix with 0.20% non-zeros (1958 entries)\n",
            "Generated matrix with 0.21% non-zeros (2070 entries)\n",
            "Generated matrix with 0.20% non-zeros (2012 entries)\n",
            "Generated matrix with 0.20% non-zeros (1976 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2012 entries)\n",
            "Generated matrix with 0.20% non-zeros (2022 entries)\n",
            "Generated matrix with 0.20% non-zeros (2004 entries)\n",
            "Generated matrix with 0.20% non-zeros (2028 entries)\n",
            "Generated matrix with 0.20% non-zeros (1958 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2034 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.19% non-zeros (1932 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (2010 entries)\n",
            "Generated matrix with 0.20% non-zeros (1956 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (2030 entries)\n",
            "Generated matrix with 0.20% non-zeros (1964 entries)\n",
            "Generated matrix with 0.20% non-zeros (2032 entries)\n",
            "Generated matrix with 0.20% non-zeros (1960 entries)\n",
            "Creating 5 samples for 'val' set (n=1000)\n",
            "Generated matrix with 0.19% non-zeros (1936 entries)\n",
            "Generated matrix with 0.20% non-zeros (2042 entries)\n",
            "Generated matrix with 0.21% non-zeros (2090 entries)\n",
            "Generated matrix with 0.19% non-zeros (1936 entries)\n",
            "Generated matrix with 0.21% non-zeros (2074 entries)\n",
            "Creating 20 samples for 'test' set (n=1000)\n",
            "Generated matrix with 0.20% non-zeros (2026 entries)\n",
            "Generated matrix with 0.20% non-zeros (2038 entries)\n",
            "Generated matrix with 0.21% non-zeros (2114 entries)\n",
            "Generated matrix with 0.20% non-zeros (2044 entries)\n",
            "Generated matrix with 0.20% non-zeros (2020 entries)\n",
            "Generated matrix with 0.20% non-zeros (1966 entries)\n",
            "Generated matrix with 0.20% non-zeros (1978 entries)\n",
            "Generated matrix with 0.19% non-zeros (1900 entries)\n",
            "Generated matrix with 0.20% non-zeros (2020 entries)\n",
            "Generated matrix with 0.20% non-zeros (2004 entries)\n",
            "Generated matrix with 0.20% non-zeros (1952 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n",
            "Generated matrix with 0.19% non-zeros (1926 entries)\n",
            "Generated matrix with 0.20% non-zeros (2000 entries)\n",
            "Generated matrix with 0.19% non-zeros (1924 entries)\n",
            "Generated matrix with 0.20% non-zeros (1988 entries)\n",
            "Generated matrix with 0.20% non-zeros (2014 entries)\n",
            "Generated matrix with 0.20% non-zeros (1982 entries)\n",
            "Generated matrix with 0.20% non-zeros (1996 entries)\n",
            "Generated matrix with 0.20% non-zeros (1990 entries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Model"
      ],
      "metadata": {
        "id": "4Jmnl78bbJzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper classes and functions"
      ],
      "metadata": {
        "id": "uVkV8IKb4uV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################\n",
        "#          Layers          #\n",
        "############################\n",
        "class GraphNet(nn.Module):\n",
        "    # Follows roughly the outline of torch_geometric.nn.MessagePassing()\n",
        "    # As shown in https://github.com/deepmind/graph_nets\n",
        "    # Here is a helpful python implementation:\n",
        "    # https://github.com/NVIDIA/GraphQSat/blob/main/gqsat/models.py\n",
        "    # Also allows multirgaph GNN via edge_2_features\n",
        "    def __init__(self, node_features, edge_features, global_features=0, hidden_size=0,\n",
        "                 aggregate=\"mean\", activation=\"relu\", skip_connection=False, edge_features_out=None):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # different aggregation functions\n",
        "        if aggregate == \"sum\":\n",
        "            self.aggregate = aggr.SumAggregation()\n",
        "        elif aggregate == \"mean\":\n",
        "            self.aggregate = aggr.MeanAggregation()\n",
        "        elif aggregate == \"max\":\n",
        "            self.aggregate = aggr.MaxAggregation()\n",
        "        elif aggregate == \"softmax\":\n",
        "            self.aggregate = aggr.SoftmaxAggregation(learn=True)\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Aggregation '{aggregate}' not implemented\")\n",
        "\n",
        "        self.global_aggregate = aggr.MeanAggregation()\n",
        "\n",
        "        add_edge_fs = 1 if skip_connection else 0\n",
        "        edge_features_out = edge_features if edge_features_out is None else edge_features_out\n",
        "\n",
        "        # Graph Net Blocks (see https://arxiv.org/pdf/1806.01261.pdf)\n",
        "        self.edge_block = MLP([global_features + (edge_features + add_edge_fs) + (2 * node_features),\n",
        "                               hidden_size,\n",
        "                               edge_features_out],\n",
        "                              activation=activation)\n",
        "\n",
        "        self.node_block = MLP([global_features + edge_features_out + node_features,\n",
        "                               hidden_size,\n",
        "                               node_features],\n",
        "                              activation=activation)\n",
        "\n",
        "        # optional set of blocks for global GNN\n",
        "        self.global_block = None\n",
        "        if global_features > 0:\n",
        "            self.global_block = MLP([edge_features_out + node_features + global_features,\n",
        "                                     hidden_size,\n",
        "                                     global_features],\n",
        "                                    activation=activation)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, g=None):\n",
        "        row, col = edge_index\n",
        "\n",
        "        if self.global_block is not None:\n",
        "            assert g is not None, \"Need global features for global block\"\n",
        "\n",
        "            # run the edge update and aggregate features\n",
        "            edge_embedding = self.edge_block(torch.cat([torch.ones(x[row].shape[0], 1, device=x.device) * g,\n",
        "                                                        x[row], x[col], edge_attr], dim=1))\n",
        "            aggregation = self.aggregate(edge_embedding, row)\n",
        "\n",
        "\n",
        "            agg_features = torch.cat([torch.ones(x.shape[0], 1, device=x.device) * g, x, aggregation], dim=1)\n",
        "            node_embeddings = self.node_block(agg_features)\n",
        "\n",
        "            # aggregate over all edges and nodes (always mean)\n",
        "            mp_global_aggr = g\n",
        "            edge_aggregation_global = self.global_aggregate(edge_embedding)\n",
        "            node_aggregation_global = self.global_aggregate(node_embeddings)\n",
        "\n",
        "            # compute the new global embedding\n",
        "            # the old global feature is part of mp_global_aggr\n",
        "            global_embeddings = self.global_block(torch.cat([node_aggregation_global,\n",
        "                                                             edge_aggregation_global,\n",
        "                                                             mp_global_aggr], dim=1))\n",
        "\n",
        "            return edge_embedding, node_embeddings, global_embeddings\n",
        "\n",
        "        else:\n",
        "            # update edge features and aggregate\n",
        "            edge_embedding = self.edge_block(torch.cat([x[row], x[col], edge_attr], dim=1))\n",
        "            aggregation = self.aggregate(edge_embedding, row)\n",
        "            agg_features = torch.cat([x, aggregation], dim=1)\n",
        "            # update node features\n",
        "            node_embeddings = self.node_block(agg_features)\n",
        "            return edge_embedding, node_embeddings, None\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, width, layer_norm=False, activation=\"relu\", activate_final=False):\n",
        "        super().__init__()\n",
        "        width = list(filter(lambda x: x > 0, width))\n",
        "        assert len(width) >= 2, \"Need at least one layer in the network!\"\n",
        "\n",
        "        lls = nn.ModuleList()\n",
        "        for k in range(len(width)-1):\n",
        "            lls.append(nn.Linear(width[k], width[k+1], bias=True))\n",
        "            if k != (len(width)-2) or activate_final:\n",
        "                if activation == \"relu\":\n",
        "                    lls.append(nn.ReLU())\n",
        "                elif activation == \"tanh\":\n",
        "                    lls.append(nn.Tanh())\n",
        "                elif activation == \"leakyrelu\":\n",
        "                    lls.append(nn.LeakyReLU())\n",
        "                elif activation == \"sigmoid\":\n",
        "                    lls.append(nn.Sigmoid())\n",
        "                else:\n",
        "                    raise NotImplementedError(f\"Activation '{activation}' not implemented\")\n",
        "\n",
        "        if layer_norm:\n",
        "            lls.append(nn.LayerNorm(width[-1]))\n",
        "\n",
        "        self.m = nn.Sequential(*lls)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.m(x)\n",
        "\n",
        "\n",
        "class MP_Block(nn.Module):\n",
        "    # L@L.T matrix multiplication graph layer\n",
        "    # Aligns the computation of L@L.T - A with the learned updates\n",
        "    def __init__(self, skip_connections, first, last, edge_features, node_features, global_features, hidden_size, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # first and second aggregation\n",
        "        if \"aggregate\" in kwargs and kwargs[\"aggregate\"] is not None:\n",
        "            aggr = kwargs[\"aggregate\"] if len(kwargs[\"aggregate\"]) == 2 else kwargs[\"aggregate\"] * 2\n",
        "        else:\n",
        "            aggr = [\"mean\", \"sum\"]\n",
        "\n",
        "        act = kwargs[\"activation\"] if \"activation\" in kwargs else \"relu\"\n",
        "\n",
        "        edge_features_in = 1 if first else edge_features\n",
        "        edge_features_out = 1 if last else edge_features\n",
        "\n",
        "        # We use 2 graph nets in order to operate on the upper and lower triangular parts of the matrix\n",
        "        self.l1 = GraphNet(node_features=node_features, edge_features=edge_features_in, global_features=global_features,\n",
        "                           hidden_size=hidden_size, skip_connection=(not first and skip_connections),\n",
        "                           aggregate=aggr[0], activation=act, edge_features_out=edge_features)\n",
        "\n",
        "        self.l2 = GraphNet(node_features=node_features, edge_features=edge_features, global_features=global_features,\n",
        "                           hidden_size=hidden_size, aggregate=aggr[1], activation=act, edge_features_out=edge_features_out)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, global_features):\n",
        "        edge_embedding, node_embeddings, global_features = self.l1(x, edge_index, edge_attr, g=global_features)\n",
        "\n",
        "        # flip row and column indices\n",
        "        edge_index = torch.stack([edge_index[1], edge_index[0]], dim=0)\n",
        "        edge_embedding, node_embeddings, global_features = self.l2(node_embeddings, edge_index, edge_embedding, g=global_features)\n",
        "\n",
        "        return edge_embedding, node_embeddings, global_features\n",
        "\n",
        "############################\n",
        "#         HELPERS          #\n",
        "############################\n",
        "def augment_features(data, skip_rhs=False):\n",
        "    # transform nodes to include more features\n",
        "\n",
        "    if skip_rhs:\n",
        "        # use instead notde position as an input feature!\n",
        "        data.x = torch.arange(data.x.size()[0], device=data.x.device).unsqueeze(1)\n",
        "\n",
        "    data = torch_geometric.transforms.LocalDegreeProfile()(data)\n",
        "\n",
        "    # diagonal dominance and diagonal decay from the paper\n",
        "    row, col = data.edge_index\n",
        "    diag = (row == col)\n",
        "    diag_elem = torch.abs(data.edge_attr[diag])\n",
        "    # remove diagonal elements by setting them to zero\n",
        "    non_diag_elem = data.edge_attr.clone()\n",
        "    non_diag_elem[diag] = 0\n",
        "\n",
        "    row_sums = aggr.SumAggregation()(torch.abs(non_diag_elem), row)\n",
        "    alpha = diag_elem / row_sums\n",
        "    row_dominance_feature = alpha / (alpha + 1)\n",
        "    row_dominance_feature = torch.nan_to_num(row_dominance_feature, nan=1.0)\n",
        "\n",
        "    # compute diagonal decay features\n",
        "    row_max = aggr.MaxAggregation()(torch.abs(non_diag_elem), row)\n",
        "    alpha = diag_elem / row_max\n",
        "    row_decay_feature = alpha / (alpha + 1)\n",
        "    row_decay_feature = torch.nan_to_num(row_decay_feature, nan=1.0)\n",
        "\n",
        "    data.x = torch.cat([data.x, row_dominance_feature, row_decay_feature], dim=1)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "class ToLowerTriangular(torch_geometric.transforms.BaseTransform):\n",
        "    def __init__(self, inplace=False):\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def __call__(self, data, order=None):\n",
        "        if not self.inplace:\n",
        "            data = data.clone()\n",
        "\n",
        "        # TODO: if order is given use that one instead\n",
        "        if order is not None:\n",
        "            raise NotImplementedError(\"Custom ordering not yet implemented...\")\n",
        "\n",
        "        # transform the data into lower triag graph\n",
        "        # this should be a data transformation (maybe?)\n",
        "        rows, cols = data.edge_index[0], data.edge_index[1]\n",
        "        fil = cols <= rows\n",
        "        l_index = data.edge_index[:, fil]\n",
        "        edge_embedding = data.edge_attr[fil]\n",
        "\n",
        "        data.edge_index, data.edge_attr = l_index, edge_embedding\n",
        "        return data"
      ],
      "metadata": {
        "id": "tB5GbXVa4xrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Preconditioner:\n",
        "    def __init__(self, A, **kwargs):\n",
        "        self.breakdown = False\n",
        "        self.nnz = 0\n",
        "        self.time = 0\n",
        "        self.n = kwargs.get(\"n\", 0)\n",
        "\n",
        "    def timed_setup(self, A, **kwargs):\n",
        "        start = time_function()\n",
        "        self.setup(A, **kwargs)\n",
        "        stop = time_function()\n",
        "        self.time = stop - start\n",
        "\n",
        "    def get_inverse(self):\n",
        "        ones = torch.ones(self.n)\n",
        "        offset = torch.zeros(1).to(torch.int64)\n",
        "\n",
        "        I = torch.sparse.spdiags(ones, offset, (self.n, self.n))\n",
        "        I = I.to(torch.float64)\n",
        "\n",
        "        return I\n",
        "\n",
        "    def get_p_matrix(self):\n",
        "        return self.get_inverse()\n",
        "\n",
        "    def check_breakdown(self, P):\n",
        "        if np.isnan(np.min(P)):\n",
        "            self.breakdown = True\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return x\n",
        "\n",
        "class LearnedPreconditioner(Preconditioner):\n",
        "    def __init__(self, data, model, **kwargs):\n",
        "        super().__init__(data, **kwargs)\n",
        "\n",
        "        self.model = model\n",
        "        self.spd = isinstance(model, NeuralIF)\n",
        "\n",
        "        self.timed_setup(data, **kwargs)\n",
        "\n",
        "        # count non‐zeros in a torch Tensor / sparse tensor\n",
        "        def count_nnz(tensor):\n",
        "            if tensor.layout == torch.sparse_coo:\n",
        "                # number of nonzero entries in a sparse_coo_tensor\n",
        "                return int(tensor._values().numel())\n",
        "            else:\n",
        "                # dense tensor: count != 0\n",
        "                return int((tensor != 0).sum().item())\n",
        "\n",
        "        if self.spd:\n",
        "            self.nnz = count_nnz(self.L)\n",
        "        else:\n",
        "            nnz_L = count_nnz(self.L)\n",
        "            nnz_U = count_nnz(self.U)\n",
        "            # subtract the diagonal entries once:\n",
        "            self.nnz = nnz_L + nnz_U - int(data.x.size(0))\n",
        "\n",
        "        # if self.spd:\n",
        "        #     self.nnz = self.L.nnz\n",
        "        # else:\n",
        "        #     self.nnz = self.L.nnz + self.U.nnz - data.x.shape[0]\n",
        "\n",
        "    def setup(self, data, **kwargs):\n",
        "        L, U, _ = self.model(data)\n",
        "\n",
        "        self.L = L.to(\"cpu\").to(torch.float64)\n",
        "        self.U = U.to(\"cpu\").to(torch.float64)\n",
        "\n",
        "    def get_inverse(self):\n",
        "        L_inv = torch.inverse(self.L.to_dense())\n",
        "        U_inv = torch.inverse(self.U.to_dense())\n",
        "\n",
        "        return U_inv@L_inv\n",
        "\n",
        "    def get_p_matrix(self):\n",
        "        return self.L@self.U\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return fb_solve(self.L, self.U, x, unit_upper=not self.spd)\n",
        "\n",
        "\n",
        "def fb_solve(L, U, r, unit_lower=False, unit_upper=False):\n",
        "    print(L)\n",
        "    y = L.solve_triangular(upper=False, unit=unit_lower, b=r)\n",
        "    z = U.solve_triangular(upper=True, unit=unit_upper, b=y)\n",
        "    return z\n",
        "\n",
        "time_function = lambda: time.perf_counter()"
      ],
      "metadata": {
        "id": "bx6j4iRY-XYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions\n",
        "@torch.no_grad()\n",
        "def validate(model, validation_loader, solve=False, solver=\"cg\"):\n",
        "    model.eval()\n",
        "    acc_loss = 0.0\n",
        "    num_loss = 0\n",
        "    acc_solver_iters = 0.0\n",
        "\n",
        "    for data in validation_loader:\n",
        "        data = data.to(device)\n",
        "        A, b = graph_to_matrix(data)\n",
        "\n",
        "        if solve:\n",
        "            preconditioner = LearnedPreconditioner(data, model)\n",
        "            print(preconditioner)\n",
        "            A_cpu = A.cpu().double()\n",
        "            b_cpu = b.cpu().double()\n",
        "            x0 = None\n",
        "\n",
        "            start = time.time()\n",
        "            if solver == \"cg\":\n",
        "                iters, x_hat = preconditioned_conjugate_gradient(\n",
        "                    A_cpu, b_cpu, M=preconditioner, x0=x0,\n",
        "                    rtol=1e-6, max_iter=1000\n",
        "                )\n",
        "            else:\n",
        "                iters, x_hat = gmres(\n",
        "                    A_cpu, b_cpu, M=preconditioner, x0=x0,\n",
        "                    atol=1e-6, max_iter=1000, left=False\n",
        "                )\n",
        "            acc_solver_iters += len(iters) - 1\n",
        "        else:\n",
        "            output, _, _ = model(data)\n",
        "            # l = frobenius_loss(output, A)\n",
        "            l = loss(data, output, config=\"frobenius\")\n",
        "            acc_loss += l.item()\n",
        "            num_loss += 1\n",
        "\n",
        "    if solve:\n",
        "        avg_iters = acc_solver_iters / len(validation_loader)\n",
        "        print(f\"Validation iterations: {avg_iters:.2f}\")\n",
        "        return avg_iters\n",
        "    else:\n",
        "        avg_loss = acc_loss / num_loss\n",
        "        print(f\"Validation loss: {avg_loss:.4f}\")\n",
        "        return avg_loss"
      ],
      "metadata": {
        "id": "bRETenOFREJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NeuralIF model"
      ],
      "metadata": {
        "id": "6pz6E3na4ruX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralIF(nn.Module):\n",
        "    # Neural Incomplete factorization\n",
        "    def __init__(self, drop_tol=0, **kwargs) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.global_features = kwargs[\"global_features\"]\n",
        "        self.latent_size = kwargs[\"latent_size\"]\n",
        "        # node features are augmented with local degree profile\n",
        "        self.augment_node_features = kwargs[\"augment_nodes\"]\n",
        "\n",
        "        num_node_features = 8 if self.augment_node_features else 1\n",
        "        message_passing_steps = kwargs[\"message_passing_steps\"]\n",
        "\n",
        "        # edge feature representation in the latent layers\n",
        "        edge_features = kwargs.get(\"edge_features\", 1)\n",
        "\n",
        "        self.skip_connections = kwargs[\"skip_connections\"]\n",
        "\n",
        "        self.mps = torch.nn.ModuleList()\n",
        "        for l in range(message_passing_steps):\n",
        "            # skip connections are added to all layers except the first one\n",
        "            self.mps.append(MP_Block(skip_connections=self.skip_connections,\n",
        "                                     first=l==0,\n",
        "                                     last=l==(message_passing_steps-1),\n",
        "                                     edge_features=edge_features,\n",
        "                                     node_features=num_node_features,\n",
        "                                     global_features=self.global_features,\n",
        "                                     hidden_size=self.latent_size,\n",
        "                                     activation=kwargs[\"activation\"],\n",
        "                                     aggregate=kwargs[\"aggregate\"]))\n",
        "\n",
        "        # node decodings\n",
        "        self.node_decoder = MLP([num_node_features, self.latent_size, 1]) if kwargs[\"decode_nodes\"] else None\n",
        "\n",
        "        # diag-aggregation for normalization of rows\n",
        "        self.normalize_diag = kwargs[\"normalize_diag\"] if \"normalize_diag\" in kwargs else False\n",
        "        self.diag_aggregate = aggr.SumAggregation()\n",
        "\n",
        "        # normalization\n",
        "        self.graph_norm = pyg.norm.GraphNorm(num_node_features) if (\"graph_norm\" in kwargs and kwargs[\"graph_norm\"]) else None\n",
        "\n",
        "        # drop tolerance and additional fill-ins and more sparsity\n",
        "        self.tau = drop_tol\n",
        "        self.two = kwargs.get(\"two_hop\", False)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # ! data could be batched here...(not implemented)\n",
        "\n",
        "        if self.augment_node_features:\n",
        "            data = augment_features(data, skip_rhs=True)\n",
        "\n",
        "        # add additional edges to the data\n",
        "        if self.two:\n",
        "            data = TwoHop()(data)\n",
        "\n",
        "        # * in principle it is possible to integrate reordering here.\n",
        "\n",
        "        data = ToLowerTriangular()(data)\n",
        "\n",
        "        # get the input data\n",
        "        edge_embedding = data.edge_attr\n",
        "        l_index = data.edge_index\n",
        "\n",
        "        if self.graph_norm is not None:\n",
        "            node_embedding = self.graph_norm(data.x, batch=data.batch)\n",
        "        else:\n",
        "            node_embedding = data.x\n",
        "\n",
        "        # copy the input data (only edges of original matrix A)\n",
        "        a_edges = edge_embedding.clone()\n",
        "\n",
        "        if self.global_features > 0:\n",
        "            global_features = torch.zeros((1, self.global_features), device=data.x.device, requires_grad=False)\n",
        "            # feature ideas: nnz, 1-norm, inf-norm col/row var, min/max variability, avg distances to nnz\n",
        "        else:\n",
        "            global_features = None\n",
        "\n",
        "        # compute the output of the network\n",
        "        for i, layer in enumerate(self.mps):\n",
        "            if i != 0 and self.skip_connections:\n",
        "                edge_embedding = torch.cat([edge_embedding, a_edges], dim=1)\n",
        "\n",
        "            edge_embedding, node_embedding, global_features = layer(node_embedding, l_index, edge_embedding, global_features)\n",
        "\n",
        "        # transform the output into a matrix\n",
        "        return self.transform_output_matrix(node_embedding, l_index, edge_embedding, a_edges)\n",
        "\n",
        "    def transform_output_matrix(self, node_x, edge_index, edge_values, a_edges):\n",
        "        # force diagonal to be positive\n",
        "        diag = edge_index[0] == edge_index[1]\n",
        "\n",
        "        # normalize diag such that it has zero residual\n",
        "        if self.normalize_diag:\n",
        "            # copy the diag of matrix A\n",
        "            a_diag = a_edges[diag]\n",
        "\n",
        "            # compute the row norm\n",
        "            square_values = torch.pow(edge_values, 2)\n",
        "            aggregated = self.diag_aggregate(square_values, edge_index[0])\n",
        "\n",
        "            # now, we renormalize the edge values such that they are the square root of the original value...\n",
        "            edge_values = torch.sqrt(a_diag[edge_index[0]]) * edge_values / torch.sqrt(aggregated[edge_index[0]])\n",
        "\n",
        "        else:\n",
        "            # otherwise, just take the edge values as they are...\n",
        "            # but take the square root as it is numerically better\n",
        "            # edge_values[diag] = torch.exp(edge_values[diag])\n",
        "            edge_values[diag] = torch.sqrt(torch.exp(edge_values[diag]))\n",
        "\n",
        "        # node decoder\n",
        "        node_output = self.node_decoder(node_x).squeeze() if self.node_decoder is not None else None\n",
        "\n",
        "        # ! this if should only be activated when the model is in production!!\n",
        "        if torch.is_inference_mode_enabled():\n",
        "\n",
        "            # we can decide to remove small elements during inference from the preconditioner matrix\n",
        "            if self.tau != 0:\n",
        "                small_value = (torch.abs(edge_values) <= self.tau).squeeze()\n",
        "\n",
        "                # small value and not diagonal\n",
        "                elems = torch.logical_and(small_value, torch.logical_not(diag))\n",
        "\n",
        "                # might be able to do this easily!\n",
        "                edge_values[elems] = 0\n",
        "\n",
        "                # remove zeros from the sparse representation\n",
        "                filt = (edge_values != 0).squeeze()\n",
        "                edge_values = edge_values[filt]\n",
        "                edge_index = edge_index[:, filt]\n",
        "\n",
        "            # ! this is the way to go!!\n",
        "            # Doing pytorch -> scipy -> numml is a lot faster than pytorch -> numml on CPU\n",
        "            # On GPU it is faster to go to pytorch -> numml -> CPU\n",
        "\n",
        "            # convert to scipy sparse matrix\n",
        "            # m = to_scipy_sparse_matrix(edge_index, matrix_values)\n",
        "            m = torch.sparse_coo_tensor(edge_index, edge_values.squeeze(),\n",
        "                                        size=(node_x.size()[0], node_x.size()[0]))\n",
        "                                        # type=torch.double)\n",
        "\n",
        "            # produce L and U seperatly\n",
        "            l = SparseCSRTensor(m)\n",
        "            u = SparseCSRTensor(m.T)\n",
        "\n",
        "            return l, u, node_output\n",
        "\n",
        "        else:\n",
        "            # For training and testing (computing regular losses for examples.)\n",
        "            # does not need to be performance optimized!\n",
        "            # use torch sparse directly\n",
        "            t = torch.sparse_coo_tensor(edge_index, edge_values.squeeze(),\n",
        "                                        size=(node_x.size()[0], node_x.size()[0]))\n",
        "\n",
        "            # normalized l1 norm is best computed here!\n",
        "            # l2_nn = torch.linalg.norm(edge_values, ord=2)\n",
        "            l1_penalty = torch.sum(torch.abs(edge_values)) / len(edge_values)\n",
        "\n",
        "            return t, l1_penalty, node_output\n"
      ],
      "metadata": {
        "id": "fo19YfVkW3cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training"
      ],
      "metadata": {
        "id": "C_ySuevTbPWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Training Configuration"
      ],
      "metadata": {
        "id": "p9Rge5QlbVmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"name\": \"experiment_1\",\n",
        "    \"save\": True,\n",
        "    \"seed\": 42,\n",
        "    \"n\": 0,\n",
        "    \"batch_size\": 1,\n",
        "    \"num_epochs\": 100,\n",
        "    \"dataset\": \"random\",\n",
        "    \"loss\": \"frobenius\",\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"regularizer\": 0.0,\n",
        "    \"scheduler\": False,\n",
        "    \"model\": \"neuralif\",\n",
        "    \"normalize\": False,\n",
        "    \"latent_size\": 8,\n",
        "    \"message_passing_steps\": 3,\n",
        "    \"decode_nodes\": False,\n",
        "    \"normalize_diag\": False,\n",
        "    \"aggregate\": [\"mean\", \"sum\"],\n",
        "    \"activation\": \"relu\",\n",
        "    \"skip_connections\": True,\n",
        "    \"augment_nodes\": False,\n",
        "    \"global_features\": 0,\n",
        "    \"edge_features\": 1,\n",
        "    \"graph_norm\": False,\n",
        "    \"two_hop\": False,\n",
        "    \"num_neighbors\": [15, 10]  # number of neighbours to sample in each hop (GraphSAGE sampling)\n",
        "}\n",
        "\n",
        "# Prepare output folder\n",
        "if config[\"name\"]:\n",
        "    folder = f\"results/{config['name']}\"\n",
        "else:\n",
        "    folder = datetime.datetime.now().strftime(\"results/%Y-%m-%d_%H-%M-%S\")\n",
        "if config[\"save\"]:\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    save_dict_to_file(config, os.path.join(folder, \"config.json\"))\n"
      ],
      "metadata": {
        "id": "Og3JzHyyQ5-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed for reproducibility\n",
        "torch_geometric.seed_everything(config[\"seed\"])\n",
        "\n",
        "# Select model\n",
        "model_args = {k: config[k] for k in [\n",
        "    \"latent_size\", \"message_passing_steps\", \"skip_connections\",\n",
        "    \"augment_nodes\", \"global_features\", \"decode_nodes\",\n",
        "    \"normalize_diag\", \"activation\", \"aggregate\", \"graph_norm\",\n",
        "    \"two_hop\", \"edge_features\", \"normalize\"\n",
        "] if k in config}\n",
        "\n",
        "use_gmres = False\n",
        "if config[\"model\"] == \"__\":\n",
        "    model = NeuralPCG(**model_args)\n",
        "elif config[\"model\"] in (\"nif\", \"neuralif\", \"inf\"):\n",
        "    model = NeuralIF(**model_args)\n",
        "else:\n",
        "    raise ValueError(\"Unknown model type\")\n",
        "\n",
        "model.to(device)\n",
        "print(\"Number of parameters:\", count_parameters(model))\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.5, patience=20\n",
        ")"
      ],
      "metadata": {
        "id": "tJnpsDJBRzJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f057b08b-9108-4226-dccd-8a447ac826e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader using NeighborLoader (GraphSAGE-inspired)\n",
        "- Random sampling of nodes at each layer to form a node's local neighbourhood"
      ],
      "metadata": {
        "id": "F8MkpyO6xvfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of all files from directory in .pt format. each file represents 1 graph\n",
        "train_dataset = FolderDataset(f\"./data/Random/train/\", n=config[\"n\"], graph=True, size=None)\n",
        "val_dataset   = FolderDataset(f\"./data/Random/val/\",   n=config[\"n\"], graph=True, size=None)\n",
        "train_files = train_dataset.files\n",
        "val_files   = val_dataset.files\n",
        "\n",
        "# place all graphs into a list\n",
        "train_graphs = [torch.load(path, weights_only=False) for path in train_files]\n",
        "val_graphs   = [torch.load(path, weights_only=False) for path in val_files]\n",
        "\n",
        "# combine all graphs into a single (disconnected) graph\n",
        "big_train_data = Batch.from_data_list(train_graphs)\n",
        "big_val_data   = Batch.from_data_list(val_graphs)\n",
        "\n",
        "# load sampled minigraphs for the train dataloader\n",
        "train_loader = NeighborLoader(\n",
        "    data=big_train_data,\n",
        "    input_nodes=None,\n",
        "    num_neighbors=config['num_neighbors'],\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "print(train_loader.data[0]) # accesses the big_train_data[0]\n",
        "print(len(train_loader))\n",
        "\n",
        "# load the full graph for the validation dataloader\n",
        "validation_loader = get_dataloader(config[\"dataset\"], config[\"n\"], 1, spd=(not gmres), mode=\"val\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "FsP6Pt5Xxmar",
        "outputId": "c8474512-5065-4999-a2e9-94ed81d4c82f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'FolderDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2176471386>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get list of all files from directory in .pt format. each file represents 1 graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFolderDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./data/Random/train/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_dataset\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mFolderDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"./data/Random/val/\"\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_files\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'FolderDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader for full graph"
      ],
      "metadata": {
        "id": "TSQKWRx5xvz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. retrieve the FolderDataset object for each of train and validation loader based on .pt files\n",
        "# 2. pass the FolderDataset object into torch.util's DataLoader as the dataset field\n",
        "# 3. return this DataLoader object\n",
        "\n",
        "# the loader below passes train_dataset directly to torch.util's DataLoader class\n",
        "\n",
        "train_loader = get_dataloader(config[\"dataset\"], config[\"n\"], config[\"batch_size\"],\n",
        "                                  spd=not gmres, mode=\"train\")\n",
        "\n",
        "print(train_loader.dataset[0])\n",
        "print(len(train_loader))\n",
        "\n",
        "validation_loader = get_dataloader(config[\"dataset\"], config[\"n\"], 1, spd=(not gmres), mode=\"val\")"
      ],
      "metadata": {
        "id": "vknOPTMW-9MU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2505566-1b66-4510-e035-04084f029f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[1000, 1], edge_index=[2, 2038], edge_attr=[2038, 1], s=[1000], n=1000)\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.utils import add_self_loops\n",
        "# training loop\n",
        "best_val = float(\"inf\")\n",
        "logger = TrainResults(folder)\n",
        "total_it = 0\n",
        "\n",
        "for epoch in range(config[\"num_epochs\"]):\n",
        "    running_loss = 0.0\n",
        "    start_epoch = time.perf_counter()\n",
        "\n",
        "    for data in train_loader:\n",
        "        total_it += 1\n",
        "        model.train()\n",
        "\n",
        "        start = time.perf_counter()\n",
        "        data = data.to(device)\n",
        "\n",
        "        # ### resolving the unmatching dimension bug for NeighborLoader class\n",
        "        # # 1) override n properly\n",
        "        # data.n = int(data.x.size(0))\n",
        "\n",
        "        # # 2) add self-loops so each node has at least one incoming edge\n",
        "        # data.edge_index, data.edge_attr = add_self_loops(\n",
        "        #     data.edge_index,\n",
        "        #     data.edge_attr,\n",
        "        #     fill_value=0.0,\n",
        "        #     num_nodes=data.n\n",
        "        # )\n",
        "        # ###\n",
        "\n",
        "        output, reg, _ = model(data)\n",
        "        l = loss(output, data, c=reg, config=config[\"loss\"])\n",
        "        l.backward()\n",
        "\n",
        "        # gradient clipping or manual norm\n",
        "        if config[\"gradient_clipping\"]:\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                model.parameters(), config[\"gradient_clipping\"]\n",
        "            )\n",
        "        else:\n",
        "            total_norm = sum(\n",
        "                p.grad.detach().data.norm(2).item() ** 2\n",
        "                for p in model.parameters() if p.grad is not None\n",
        "            )\n",
        "            grad_norm = (total_norm ** 0.5) / config[\"batch_size\"]\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += l.item()\n",
        "        logger.log(l.item(), grad_norm, time.perf_counter() - start)\n",
        "\n",
        "        # periodic validation\n",
        "        if total_it % 1000 == 0:\n",
        "            val_metric = validate(\n",
        "                model, validation_loader, solve=True,\n",
        "                solver=\"gmres\" if use_gmres else \"cg\"\n",
        "            )\n",
        "            logger.log_val(None, val_metric)\n",
        "            if val_metric < best_val:\n",
        "                best_val = val_metric\n",
        "                if config[\"save\"]:\n",
        "                    torch.save(model.state_dict(), f\"{folder}/best_model.pt\")\n",
        "\n",
        "    epoch_time = time.perf_counter() - start_epoch\n",
        "    print(f\"Epoch {epoch+1} — loss: {running_loss/len(train_loader):.4f}, time: {epoch_time:.1f}s\")\n",
        "    if config[\"save\"]:\n",
        "        torch.save(model.state_dict(), f\"{folder}/model_epoch{epoch+1}.pt\")\n"
      ],
      "metadata": {
        "id": "sMSaRR7cSMFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f0b1f0b8-42e9-4b51-b941-ac063dae6557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "both arguments to matmul need to be at least 1D, but they are 0D and 0D",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-1203322514>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/CS4350/project/neuralif/loss.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(output, data, config, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frobenius\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrobenius_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/CS4350/project/neuralif/loss.py\u001b[0m in \u001b[0;36mfrobenius_loss\u001b[0;34m(L, A, sparse)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mU\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: both arguments to matmul need to be at least 1D, but they are 0D and 0D"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save results\n",
        "if config[\"save\"]:\n",
        "    logger.save_results()\n",
        "    torch.save(model.to(torch.float).state_dict(), f\"{folder}/final_model.pt\")\n"
      ],
      "metadata": {
        "id": "vom7sud2SSpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test printout\n",
        "print(\"Best validation performance:\", best_val)"
      ],
      "metadata": {
        "id": "5JqtkgTZSaSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}